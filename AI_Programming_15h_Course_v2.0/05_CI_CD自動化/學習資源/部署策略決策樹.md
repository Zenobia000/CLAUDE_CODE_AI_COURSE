# 部署策略決策樹

## 🎯 策略選擇總覽

選擇正確的部署策略對於 CI/CD 成功至關重要。本指南提供決策樹和實用配置，幫助你根據專案特性選擇最適合的部署方式。

**核心原則**：
> 🔒 安全優先 > 📈 業務連續性 > ⚡ 部署速度 > 💰 資源成本

---

## 🌳 部署策略決策樹

### 第一層：業務影響評估

```
你的應用對業務的重要性？
├─ 🔴 關鍵業務系統（停機 = 重大損失）
│  └─ 必須：零停機部署
│     ├─ 藍綠部署（推薦）
│     ├─ 滾動部署
│     └─ 金絲雀部署
│
├─ 🟡 重要業務系統（停機有影響）
│  └─ 建議：低風險部署
│     ├─ 金絲雀部署（推薦）
│     ├─ 滾動部署
│     └─ 藍綠部署
│
└─ 🟢 開發/測試系統（停機可接受）
   └─ 可選：簡單部署
      ├─ 重建部署（最簡單）
      ├─ 滾動部署
      └─ 藍綠部署
```

### 第二層：技術環境評估

```
你的技術環境特性？
├─ 🐳 容器化應用
│  ├─ Kubernetes → 滾動部署/金絲雀部署
│  ├─ Docker Swarm → 滾動部署
│  └─ 單機 Docker → 藍綠部署
│
├─ ☁️ 雲端原生
│  ├─ AWS ECS/EKS → 滾動/金絲雀部署
│  ├─ Azure Container Apps → 藍綠/滾動部署
│  └─ Google Cloud Run → 流量分割部署
│
├─ 🖥️ 傳統虛擬機
│  ├─ 負載均衡器 → 藍綠部署
│  ├─ 多台伺服器 → 滾動部署
│  └─ 單台伺服器 → 重建部署
│
└─ 🌐 無伺服器 (Serverless)
   ├─ AWS Lambda → 別名/版本部署
   ├─ Azure Functions → 部署槽位
   └─ Vercel/Netlify → 預覽部署
```

### 第三層：資源限制評估

```
你的資源限制？
├─ 💰 成本敏感
│  ├─ 重建部署（成本最低）
│  ├─ 滾動部署（中等成本）
│  └─ 避免：藍綠部署（雙倍資源）
│
├─ ⚡ 速度優先
│  ├─ 藍綠部署（最快切換）
│  ├─ 重建部署（最快準備）
│  └─ 避免：金絲雀部署（逐步推出）
│
├─ 🔒 安全優先
│  ├─ 金絲雀部署（風險最小）
│  ├─ 藍綠部署（快速回退）
│  └─ 避免：重建部署（風險最高）
│
└─ 📊 監控完善
   ├─ 金絲雀部署（精細控制）
   ├─ 滾動部署（漸進監控）
   └─ 自動回退機制
```

---

## 🚀 部署策略詳解

### 1. 🔄 重建部署 (Recreate)

**適用場景**：
- 🟢 開發/測試環境
- 💰 成本敏感專案
- 🔧 可容忍短暫停機的系統

**優勢**：
- ✅ 配置最簡單
- ✅ 資源需求最少
- ✅ 問題定位容易

**劣勢**：
- ❌ 有停機時間
- ❌ 回退速度慢
- ❌ 不適合生產環境

**配置範例**：
```yaml
# GitHub Actions - 重建部署
name: Recreate Deployment

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # 停止舊服務
      - name: Stop old service
        run: |
          kubectl delete deployment myapp
          kubectl wait --for=delete pod -l app=myapp --timeout=300s

      # 部署新版本
      - name: Deploy new version
        run: |
          kubectl apply -f k8s/deployment.yml
          kubectl wait --for=condition=ready pod -l app=myapp --timeout=300s

      # 健康檢查
      - name: Health check
        run: |
          kubectl get pods -l app=myapp
          curl -f http://myapp.example.com/health
```

**決策要點**：
```
選擇重建部署當：
✅ 開發/測試環境
✅ 預算有限
✅ 團隊經驗不足
✅ 系統架構簡單

避免重建部署當：
❌ 生產環境
❌ 24/7 服務要求
❌ 用戶體驗重要
❌ 有 SLA 要求
```

### 2. 🔵🟢 藍綠部署 (Blue-Green)

**適用場景**：
- 🔴 關鍵業務系統
- ⚡ 需要快速切換
- 💰 資源充足的環境

**優勢**：
- ✅ 零停機部署
- ✅ 瞬間切換
- ✅ 快速回退
- ✅ 完整的預生產測試

**劣勢**：
- ❌ 需要雙倍資源
- ❌ 資料庫同步複雜
- ❌ 配置較複雜

**配置範例**：
```yaml
# GitHub Actions - 藍綠部署
name: Blue-Green Deployment

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # 確定當前活躍環境
      - name: Determine active environment
        id: env
        run: |
          ACTIVE=$(kubectl get service myapp -o jsonpath='{.spec.selector.version}')
          if [ "$ACTIVE" = "blue" ]; then
            echo "inactive=green" >> $GITHUB_OUTPUT
            echo "active=blue" >> $GITHUB_OUTPUT
          else
            echo "inactive=blue" >> $GITHUB_OUTPUT
            echo "active=green" >> $GITHUB_OUTPUT
          fi

      # 部署到非活躍環境
      - name: Deploy to inactive environment
        run: |
          # 更新部署配置
          sed -i "s/VERSION_PLACEHOLDER/${{ steps.env.outputs.inactive }}/g" k8s/deployment-${{ steps.env.outputs.inactive }}.yml
          kubectl apply -f k8s/deployment-${{ steps.env.outputs.inactive }}.yml

          # 等待部署完成
          kubectl wait --for=condition=ready pod -l app=myapp,version=${{ steps.env.outputs.inactive }} --timeout=600s

      # 健康檢查
      - name: Health check inactive environment
        run: |
          # 內部健康檢查
          kubectl port-forward svc/myapp-${{ steps.env.outputs.inactive }} 8080:80 &
          sleep 5
          curl -f http://localhost:8080/health

          # 煙霧測試
          curl -f http://localhost:8080/api/status

      # 切換流量
      - name: Switch traffic
        run: |
          # 更新服務指向新環境
          kubectl patch service myapp -p '{"spec":{"selector":{"version":"${{ steps.env.outputs.inactive }}"}}}'

          # 驗證切換成功
          sleep 10
          curl -f http://myapp.example.com/health

      # 清理舊環境 (可選)
      - name: Cleanup old environment
        if: success()
        run: |
          kubectl delete deployment myapp-${{ steps.env.outputs.active }}
```

**決策要點**：
```
選擇藍綠部署當：
✅ 零停機要求嚴格
✅ 有充足的資源
✅ 需要快速回退
✅ 部署頻率較低

避免藍綠部署當：
❌ 資源嚴重受限
❌ 有狀態應用複雜
❌ 資料庫遷移頻繁
❌ 成本控制嚴格
```

### 3. 🌊 滾動部署 (Rolling)

**適用場景**：
- 🔴 多實例應用
- 📊 需要逐步觀察
- 💰 資源使用平衡

**優勢**：
- ✅ 零停機部署
- ✅ 資源使用效率高
- ✅ 可觀察部署過程
- ✅ Kubernetes 原生支援

**劣勢**：
- ❌ 回退時間較長
- ❌ 部署過程中版本混合
- ❌ 複雜的狀態管理

**配置範例**：
```yaml
# Kubernetes - 滾動部署配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 6
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1      # 最多同時停止 1 個 Pod
      maxSurge: 2           # 最多同時新增 2 個 Pod
  template:
    spec:
      containers:
      - name: myapp
        image: myapp:{{ .Values.image.tag }}
        readinessProbe:      # 就緒檢查
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:       # 存活檢查
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10

---
# GitHub Actions - 滾動部署監控
name: Rolling Deployment with Monitoring

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # 更新部署
      - name: Update deployment
        run: |
          kubectl set image deployment/myapp myapp=myapp:${{ github.sha }}

      # 監控滾動更新
      - name: Monitor rollout
        run: |
          # 等待滾動更新完成
          kubectl rollout status deployment/myapp --timeout=600s

          # 檢查更新狀態
          kubectl get deployment myapp
          kubectl get pods -l app=myapp

      # 驗證部署
      - name: Verify deployment
        run: |
          # 等待所有 Pod 就緒
          kubectl wait --for=condition=ready pod -l app=myapp --timeout=300s

          # 健康檢查
          for i in {1..5}; do
            curl -f http://myapp.example.com/health
            sleep 2
          done

      # 自動回退（如果檢查失敗）
      - name: Auto rollback on failure
        if: failure()
        run: |
          echo "Deployment failed, rolling back..."
          kubectl rollout undo deployment/myapp
          kubectl rollout status deployment/myapp --timeout=300s
```

**決策要點**：
```
選擇滾動部署當：
✅ 多實例應用
✅ Kubernetes 環境
✅ 需要漸進部署
✅ 資源使用敏感

避免滾動部署當：
❌ 單實例應用
❌ 版本混合有問題
❌ 需要瞬間切換
❌ 複雜的狀態管理
```

### 4. 🐤 金絲雀部署 (Canary)

**適用場景**：
- 🔒 風險敏感系統
- 📊 需要漸進式驗證
- 🎯 A/B 測試需求

**優勢**：
- ✅ 風險最小化
- ✅ 可控制的流量分配
- ✅ 實時監控反饋
- ✅ 精細的回退控制

**劣勢**：
- ❌ 配置最複雜
- ❌ 需要進階監控
- ❌ 部署時間最長

**配置範例**：
```yaml
# Istio - 金絲雀部署配置
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: myapp
spec:
  http:
  - match:
    - headers:
        canary:
          exact: "true"
    route:
    - destination:
        host: myapp
        subset: canary
  - route:
    - destination:
        host: myapp
        subset: stable
      weight: 90  # 90% 流量到穩定版本
    - destination:
        host: myapp
        subset: canary
      weight: 10  # 10% 流量到金絲雀版本

---
# GitHub Actions - 金絲雀部署流程
name: Canary Deployment

on:
  push:
    branches: [main]

jobs:
  canary-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # 階段 1：部署金絲雀版本（5% 流量）
      - name: Deploy canary version
        run: |
          # 部署金絲雀版本
          kubectl apply -f k8s/canary-deployment.yml

          # 設定 5% 流量到金絲雀
          kubectl apply -f - <<EOF
          apiVersion: networking.istio.io/v1alpha3
          kind: VirtualService
          metadata:
            name: myapp
          spec:
            http:
            - route:
              - destination:
                  host: myapp
                  subset: stable
                weight: 95
              - destination:
                  host: myapp
                  subset: canary
                weight: 5
          EOF

      # 監控金絲雀版本（10 分鐘）
      - name: Monitor canary (Stage 1)
        run: |
          echo "Monitoring canary with 5% traffic for 10 minutes..."
          sleep 600

          # 檢查錯誤率
          ERROR_RATE=$(curl -s http://prometheus:9090/api/v1/query?query=rate\(http_requests_total\{job=\"myapp\",subset=\"canary\",status=~\"5..\"\}\[5m\]\) | jq .data.result[0].value[1])

          if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
            echo "❌ High error rate detected: $ERROR_RATE"
            exit 1
          fi

      # 階段 2：增加到 25% 流量
      - name: Increase canary traffic to 25%
        run: |
          kubectl apply -f - <<EOF
          apiVersion: networking.istio.io/v1alpha3
          kind: VirtualService
          metadata:
            name: myapp
          spec:
            http:
            - route:
              - destination:
                  host: myapp
                  subset: stable
                weight: 75
              - destination:
                  host: myapp
                  subset: canary
                weight: 25
          EOF

      # 監控擴展後的金絲雀（15 分鐘）
      - name: Monitor canary (Stage 2)
        run: |
          echo "Monitoring canary with 25% traffic for 15 minutes..."
          sleep 900

          # 綜合健康檢查
          python scripts/canary-health-check.py --threshold=0.02

      # 階段 3：完全切換到新版本
      - name: Full rollout
        run: |
          # 100% 流量切換到金絲雀（現在變成新的穩定版本）
          kubectl apply -f - <<EOF
          apiVersion: networking.istio.io/v1alpha3
          kind: VirtualService
          metadata:
            name: myapp
          spec:
            http:
            - route:
              - destination:
                  host: myapp
                  subset: canary
                weight: 100
          EOF

      # 清理舊版本
      - name: Cleanup old version
        run: |
          kubectl delete deployment myapp-stable

          # 重新標記金絲雀為穩定版本
          kubectl patch deployment myapp-canary -p '{"metadata":{"labels":{"version":"stable"}}}'

  # 自動回退任務
  rollback:
    runs-on: ubuntu-latest
    if: failure()
    needs: canary-deploy
    steps:
      - name: Emergency rollback
        run: |
          echo "🚨 Canary deployment failed, rolling back immediately"

          # 立即切換回穩定版本
          kubectl apply -f - <<EOF
          apiVersion: networking.istio.io/v1alpha3
          kind: VirtualService
          metadata:
            name: myapp
          spec:
            http:
            - route:
              - destination:
                  host: myapp
                  subset: stable
                weight: 100
          EOF

          # 清理失敗的金絲雀部署
          kubectl delete deployment myapp-canary
```

**決策要點**：
```
選擇金絲雀部署當：
✅ 風險控制重要
✅ 有完善監控
✅ 需要漸進驗證
✅ 團隊經驗豐富

避免金絲雀部署當：
❌ 監控系統不完善
❌ 團隊經驗不足
❌ 部署頻率很高
❌ 簡單的應用
```

---

## 🎯 策略選擇快速指南

### 根據應用類型選擇

| 應用類型 | 推薦策略 | 原因 |
|----------|----------|------|
| **Web 應用** | 藍綠/滾動 | 零停機要求高 |
| **API 服務** | 金絲雀/滾動 | 需要逐步驗證 |
| **微服務** | 滾動/金絲雀 | 服務間依賴複雜 |
| **單體應用** | 藍綠/重建 | 部署單位大 |
| **資料庫** | 藍綠/重建 | 狀態管理複雜 |
| **靜態網站** | 重建/藍綠 | 部署簡單 |
| **機器學習模型** | 金絲雀/藍綠 | 需要 A/B 測試 |

### 根據團隊成熟度選擇

| 團隊水平 | 推薦策略 | 學習路徑 |
|----------|----------|----------|
| **初學者** | 重建 → 滾動 | 逐步學習 Kubernetes |
| **中級** | 滾動 → 藍綠 | 掌握資源管理 |
| **高級** | 金絲雀 → 自動化 | 建立完整監控 |
| **專家** | 混合策略 | 根據場景靈活選擇 |

### 根據資源限制選擇

| 資源狀況 | 推薦策略 | 考量因素 |
|----------|----------|----------|
| **資源充足** | 藍綠部署 | 最佳用戶體驗 |
| **資源中等** | 滾動部署 | 平衡效率與體驗 |
| **資源受限** | 重建部署 | 成本優先 |
| **彈性資源** | 金絲雀部署 | 動態調整資源 |

---

## 🔧 實施建議

### 🚀 快速開始（5 分鐘）

**步驟 1：評估你的現狀**
```bash
# 快速評估腳本
#!/bin/bash
echo "🔍 部署策略評估"

# 檢查環境類型
if kubectl version &>/dev/null; then
    echo "✅ Kubernetes 環境 → 推薦滾動/金絲雀部署"
elif docker version &>/dev/null; then
    echo "✅ Docker 環境 → 推薦藍綠部署"
else
    echo "ℹ️ 傳統環境 → 推薦重建部署開始"
fi

# 檢查負載均衡
if curl -I http://your-app.com 2>/dev/null | grep -q "x-served-by"; then
    echo "✅ 有負載均衡 → 支援藍綠/滾動部署"
fi

# 檢查監控
if curl -I http://prometheus:9090 &>/dev/null; then
    echo "✅ 有監控系統 → 支援金絲雀部署"
fi
```

**步驟 2：選擇起始策略**
```
新手推薦路徑：
重建部署 (學習基礎)
    ↓
滾動部署 (零停機)
    ↓
藍綠部署 (快速切換)
    ↓
金絲雀部署 (風險控制)
```

**步驟 3：實施第一個策略**
- 選擇最簡單適用的策略
- 在測試環境先驗證
- 建立監控和告警
- 逐步應用到生產環境

### 📈 進階優化

**多策略混合使用**：
```
開發環境：重建部署（快速迭代）
    ↓
測試環境：滾動部署（模擬生產）
    ↓
預生產：金絲雀部署（風險驗證）
    ↓
生產環境：藍綠部署（零停機保障）
```

**自動化決策系統**：
```yaml
# 智能部署策略選擇
deploy_strategy:
  conditions:
    - if: environment == "production" && risk_level == "high"
      strategy: canary
      traffic_split: [5, 25, 50, 100]

    - if: environment == "production" && risk_level == "medium"
      strategy: blue_green

    - if: environment == "staging"
      strategy: rolling

    - if: environment == "development"
      strategy: recreate
```

---

## 📚 延伸學習

### 🎯 相關工具

**部署工具**：
- **Argo Rollouts**：Kubernetes 高級部署策略
- **Flagger**：自動化漸進式部署
- **Spinnaker**：多雲部署管線
- **Jenkins X**：GitOps 驅動的 CI/CD

**監控工具**：
- **Prometheus + Grafana**：指標監控
- **Jaeger**：分散式追蹤
- **Fluentd**：日誌聚合
- **Istio**：服務網格監控

### 🔗 實戰資源

- **Kubernetes 官方部署策略指南**
- **AWS/Azure/GCP 部署最佳實踐**
- **CNCF 漸進式交付白皮書**
- **Site Reliability Engineering (SRE) 部署章節**

---

**下一步**：根據決策樹選擇適合的策略，參考對應的配置範例開始實施 →