# C07ï¼šè³‡æ–™åº«é·ç§»è‡ªå‹•åŒ– â­

## ğŸ“‹ æƒ…å¢ƒè³‡è¨Š

**é›£åº¦ç­‰ç´š**ï¼šâ­â­ çµ„åˆç´š
**é ä¼°æ™‚é–“**ï¼š1.5-2 å°æ™‚
**æ ¸å¿ƒæŠ€èƒ½**ï¼šè³‡æ–™åº«é·ç§»ã€å‚™ä»½ç­–ç•¥ã€å›é€€æ©Ÿåˆ¶ã€è³‡æ–™å®Œæ•´æ€§é©—è­‰
**å‰ç½®çŸ¥è­˜**ï¼šåŸºç¤ç´š B01-B06ã€çµ„åˆç´š C04

---

## ğŸ¯ æƒ…å¢ƒèƒŒæ™¯

ä½ æ˜¯è³‡æ–™åº«å¯é æ€§å·¥ç¨‹å¸«(DBRE),è² è²¬å»ºç«‹å®‰å…¨çš„è³‡æ–™åº«é·ç§»è‡ªå‹•åŒ–ç³»çµ±ã€‚

**ä¸Šæ¬¡äº‹æ•…**ï¼š
```bash
äº‹æ•…å ±å‘Š #456
æ—¥æœŸï¼š2024-10-20
å½±éŸ¿ï¼š8 å°æ™‚åœæ©Ÿ

å•é¡Œï¼š
1. é·ç§»è…³æœ¬åˆªé™¤äº†ç”Ÿç”¢ç’°å¢ƒé—œéµæ¬„ä½
2. æ²’æœ‰å‚™ä»½
3. å›é€€è…³æœ¬æœªæ¸¬è©¦
4. è³‡æ–™éºå¤±ç„¡æ³•æ¢å¾©

æå¤±ï¼š$250,000
```

**ç›®æ¨™**ï¼šå»ºç«‹é›¶é¢¨éšªçš„è³‡æ–™åº«é·ç§»æµç¨‹

---

## ğŸ¬ éšæ®µå±•é–‹

### éšæ®µ 1ï¼šå®‰å…¨é·ç§»æ¡†æ¶ï¼ˆ30 åˆ†é˜ï¼‰

**é·ç§»è…³æœ¬ç¯„ä¾‹**ï¼ˆAlembicï¼‰ï¼š
```python
# migrations/versions/001_add_user_status.py
"""add user status column

Revision ID: 001
"""
from alembic import op
import sqlalchemy as sa

def upgrade():
    # Step 1: æ·»åŠ æ¬„ä½ï¼ˆå…è¨± NULLï¼‰
    op.add_column('users',
        sa.Column('status', sa.String(20), nullable=True)
    )
    
    # Step 2: è¨­å®šé è¨­å€¼
    op.execute("UPDATE users SET status = 'active' WHERE status IS NULL")
    
    # Step 3: è¨­ç‚º NOT NULL
    op.alter_column('users', 'status', nullable=False)
    
    # Step 4: å»ºç«‹ç´¢å¼•
    op.create_index('idx_users_status', 'users', ['status'])

def downgrade():
    # å›é€€å¿…é ˆç¶“éæ¸¬è©¦
    op.drop_index('idx_users_status')
    op.drop_column('users', 'status')
```

**é·ç§»æ¸¬è©¦**ï¼ˆ`.github/workflows/migration-test.yml`ï¼‰ï¼š
```yaml
name: Migration Test

on:
  pull_request:
    paths:
      - 'migrations/**'

jobs:
  test-migration:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: test_db
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install alembic psycopg2-binary

      - name: Load sample data
        run: |
          psql -h localhost -U postgres -d test_db < tests/fixtures/sample_data.sql

      - name: Run migration (upgrade)
        run: alembic upgrade head

      - name: Verify schema
        run: python tests/verify_schema.py

      - name: Verify data integrity
        run: python tests/verify_data.py

      - name: Test rollback
        run: alembic downgrade -1

      - name: Verify rollback
        run: python tests/verify_rollback.py

      - name: Test re-upgrade
        run: alembic upgrade head
```

**è³‡æ–™é©—è­‰è…³æœ¬**ï¼ˆ`tests/verify_data.py`ï¼‰ï¼š
```python
import sys
from sqlalchemy import create_engine, text

def verify_data_integrity():
    engine = create_engine("postgresql://postgres:test@localhost/test_db")
    
    with engine.connect() as conn:
        # æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§
        result = conn.execute(text("""
            SELECT COUNT(*) as total,
                   COUNT(status) as with_status
            FROM users
        """))
        row = result.fetchone()
        
        if row.total != row.with_status:
            print(f"âŒ Data integrity check failed: {row.with_status}/{row.total}")
            return False
        
        # æª¢æŸ¥æ¥­å‹™é‚è¼¯ç´„æŸ
        result = conn.execute(text("""
            SELECT COUNT(*) FROM users 
            WHERE status NOT IN ('active', 'inactive', 'suspended')
        """))
        invalid_count = result.scalar()
        
        if invalid_count > 0:
            print(f"âŒ Found {invalid_count} users with invalid status")
            return False
    
    print("âœ… Data integrity verified")
    return True

if __name__ == "__main__":
    success = verify_data_integrity()
    sys.exit(0 if success else 1)
```

**æª¢æŸ¥é» 1**ï¼š
- [ ] é·ç§»è…³æœ¬èƒ½æ­£ç¢ºå‡ç´š
- [ ] é·ç§»è…³æœ¬èƒ½æ­£ç¢ºå›é€€
- [ ] è³‡æ–™å®Œæ•´æ€§é©—è­‰é€šé
- [ ] Schema é©—è­‰é€šé

---

### éšæ®µ 2ï¼šç”Ÿç”¢ç’°å¢ƒå‚™ä»½ç­–ç•¥ï¼ˆ25 åˆ†é˜ï¼‰

**å‚™ä»½è‡ªå‹•åŒ–**ï¼ˆ`.github/workflows/prod-migration.yml`ï¼‰ï¼š
```yaml
name: Production Migration

on:
  workflow_dispatch:
    inputs:
      migration_id:
        description: 'Migration ID to apply'
        required: true

jobs:
  backup-and-migrate:
    runs-on: ubuntu-latest
    environment: production

    steps:
      - uses: actions/checkout@v4

      - name: Create backup
        id: backup
        run: |
          BACKUP_FILE="backup_$(date +%Y%m%d_%H%M%S).sql"
          
          pg_dump ${{ secrets.PROD_DB_URL }} > $BACKUP_FILE
          
          # å£“ç¸®å‚™ä»½
          gzip $BACKUP_FILE
          
          # ä¸Šå‚³åˆ° S3
          aws s3 cp ${BACKUP_FILE}.gz s3://backups/database/
          
          echo "backup_file=${BACKUP_FILE}.gz" >> $GITHUB_OUTPUT

      - name: Verify backup
        run: |
          # é©—è­‰å‚™ä»½æª”æ¡ˆå®Œæ•´æ€§
          gunzip -t ${{ steps.backup.outputs.backup_file }}

      - name: Apply migration
        id: migrate
        run: |
          export DATABASE_URL=${{ secrets.PROD_DB_URL }}
          alembic upgrade ${{ github.event.inputs.migration_id }}

      - name: Verify migration
        run: python tests/verify_schema.py

      - name: Rollback on failure
        if: failure()
        run: |
          echo "Migration failed. Restoring from backup..."
          
          # å¾ S3 ä¸‹è¼‰å‚™ä»½
          aws s3 cp s3://backups/database/${{ steps.backup.outputs.backup_file }} .
          
          # è§£å£“ä¸¦æ¢å¾©
          gunzip ${{ steps.backup.outputs.backup_file }}
          psql ${{ secrets.PROD_DB_URL }} < ${BACKUP_FILE%.gz}
          
          echo "Database restored successfully"

      - name: Notify team
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Production migration ${{ github.event.inputs.migration_id }}'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

**æª¢æŸ¥é» 2**ï¼š
- [ ] å‚™ä»½è‡ªå‹•å»ºç«‹
- [ ] å‚™ä»½ä¸Šå‚³åˆ°å®‰å…¨å„²å­˜
- [ ] å‚™ä»½é©—è­‰é€šé
- [ ] å¤±æ•—æ™‚è‡ªå‹•å›é€€

---

### éšæ®µ 3ï¼šé›¶åœæ©Ÿé·ç§»ç­–ç•¥ï¼ˆ20 åˆ†é˜ï¼‰

**è—ç¶ éƒ¨ç½²è³‡æ–™åº«é·ç§»**ï¼š
```python
# migrations/versions/002_zero_downtime_rename.py
"""rename column with zero downtime

æ­¥é©Ÿï¼š
1. æ·»åŠ æ–°æ¬„ä½
2. é›™å¯«ï¼ˆåŒæ™‚å¯«å…¥èˆŠæ¬„ä½å’Œæ–°æ¬„ä½ï¼‰
3. è³‡æ–™å›å¡«
4. åˆ‡æ›è®€å–åˆ°æ–°æ¬„ä½
5. åˆªé™¤èˆŠæ¬„ä½
"""
from alembic import op
import sqlalchemy as sa

def upgrade():
    # Phase 1: æ·»åŠ æ–°æ¬„ä½
    op.add_column('products',
        sa.Column('description_new', sa.Text, nullable=True)
    )
    
    # Phase 2: è³‡æ–™å›å¡«
    op.execute("""
        UPDATE products 
        SET description_new = description 
        WHERE description_new IS NULL
    """)
    
    # Phase 3: è¨­ç‚º NOT NULLï¼ˆæ­¤æ™‚æ‡‰ç”¨å·²åˆ‡æ›åˆ°æ–°æ¬„ä½ï¼‰
    op.alter_column('products', 'description_new', nullable=False)
    
    # Phase 4: é‡å‘½åï¼ˆå¯é¸ï¼Œæˆ–ä¿ç•™èˆŠæ¬„ä½ä¸€æ®µæ™‚é–“ï¼‰
    # op.alter_column('products', 'description_new', new_column_name='description_v2')

def downgrade():
    # å›é€€ç­–ç•¥
    op.drop_column('products', 'description_new')
```

**æ‡‰ç”¨å±¤é›™å¯«é‚è¼¯**ï¼š
```python
# app/models/product.py
class Product(Base):
    __tablename__ = 'products'
    
    id = Column(Integer, primary_key=True)
    description = Column(Text)  # èˆŠæ¬„ä½
    description_new = Column(Text)  # æ–°æ¬„ä½
    
    @validates('description_new')
    def update_description(self, key, value):
        # é›™å¯«ï¼šåŒæ™‚æ›´æ–°å…©å€‹æ¬„ä½
        self.description = value
        return value
    
    @property
    def active_description(self):
        # Feature flag æ§åˆ¶è®€å–å“ªå€‹æ¬„ä½
        if os.getenv('USE_NEW_DESCRIPTION') == 'true':
            return self.description_new
        return self.description
```

**æª¢æŸ¥é» 3**ï¼š
- [ ] é›¶åœæ©Ÿé·ç§»ç­–ç•¥å¯¦æ–½
- [ ] é›™å¯«é‚è¼¯æ­£ç¢º
- [ ] Feature flag æ§åˆ¶åˆ‡æ›
- [ ] è³‡æ–™ä¸€è‡´æ€§ç¶­æŒ

---

### éšæ®µ 4ï¼šç›£æ§èˆ‡å‘Šè­¦ï¼ˆ10 åˆ†é˜ï¼‰

**é·ç§»ç›£æ§**ï¼š
```yaml
- name: Monitor migration progress
  run: |
    # ç›£æ§é•·æ™‚é–“é‹è¡Œçš„æŸ¥è©¢
    psql ${{ secrets.PROD_DB_URL }} -c "
      SELECT pid, now() - query_start as duration, query 
      FROM pg_stat_activity 
      WHERE query NOT LIKE '%pg_stat_activity%'
      ORDER BY duration DESC;
    "
    
    # ç›£æ§é–å®š
    psql ${{ secrets.PROD_DB_URL }} -c "
      SELECT * FROM pg_locks WHERE NOT granted;
    "
    
    # ç›£æ§è³‡æ–™åº«å¤§å°
    psql ${{ secrets.PROD_DB_URL }} -c "
      SELECT pg_size_pretty(pg_database_size('production_db'));
    "
```

**æª¢æŸ¥é» 4**ï¼š
- [ ] é·ç§»é€²åº¦å¯è¦‹
- [ ] é–å®šç›£æ§å°±ç·’
- [ ] æ•ˆèƒ½å½±éŸ¿å¯æ§
- [ ] å‘Šè­¦æ­£ç¢ºè§¸ç™¼

---

## ğŸ¯ å­¸ç¿’æª¢æŸ¥é»

### æŠ€è¡“èƒ½åŠ›
- [ ] å¯¦ç¾å®‰å…¨é·ç§»æ¡†æ¶
- [ ] å»ºç«‹è‡ªå‹•å‚™ä»½ç³»çµ±
- [ ] å¯¦ç¾é›¶åœæ©Ÿé·ç§»
- [ ] å®Œæˆç›£æ§èˆ‡å‘Šè­¦

### å®‰å…¨æŒ‡æ¨™
- [ ] 100% é·ç§»æ¸¬è©¦è¦†è“‹
- [ ] å‚™ä»½é©—è­‰é€šéç‡ 100%
- [ ] é›¶è³‡æ–™éºå¤±
- [ ] å›é€€æ™‚é–“ < 5 åˆ†é˜

---

## ğŸ’¡ å»¶ä¼¸æŒ‘æˆ°

### æŒ‘æˆ° 1ï¼šå¤§è¡¨é·ç§»å„ªåŒ–
- åˆ†æ‰¹é·ç§»ç™¾è¬ç´šè³‡æ–™
- æœ€å°åŒ–é–å®šæ™‚é–“
- é€²åº¦è¿½è¹¤

### æŒ‘æˆ° 2ï¼šå¤šè³‡æ–™åº«å”èª¿é·ç§»
- å¾®æœå‹™å¤šè³‡æ–™åº«
- äº‹å‹™ä¸€è‡´æ€§
- åˆ†æ•£å¼é–

### æŒ‘æˆ° 3ï¼šè‡ªå‹•åŒ–æ¸¬è©¦è³‡æ–™ç”Ÿæˆ
- ç”¢ç”Ÿæ¸¬è©¦è³‡æ–™é›†
- å£“åŠ›æ¸¬è©¦
- é‚Šç•Œæƒ…æ³æ¸¬è©¦

---

## ğŸ“š åƒè€ƒè³‡æº

- [Alembic æ–‡æª”](https://alembic.sqlalchemy.org/)
- [Zero-Downtime Migrations](https://github.com/ankane/strong_migrations)
- [Database Reliability Engineering](https://www.oreilly.com/library/view/database-reliability-engineering/9781491925935/)

---

**ä¸‹ä¸€æ­¥**ï¼šå®Œæˆå¾Œå¯æŒ‘æˆ° **C08ï¼šæ•ˆèƒ½æ¸¬è©¦æ•´åˆ** æˆ– **E02ï¼šå¾®æœå‹™æ¶æ§‹ CI/CD**ï¼
