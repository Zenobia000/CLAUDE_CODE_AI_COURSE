# 隱私保護工作流

> **學習目標**: 建立與 AI 互動前的隱私保護習慣，掌握敏感資訊識別與清理方法

---

## 核心原則

> **「分享代碼前，先問：這裡有我不想公開在 Reddit 上的資訊嗎？」**

### 為什麼需要隱私保護？

**真實事件**: 2023 年 4 月，三星員工使用 ChatGPT 優化內部代碼時，意外分享了：
- 新產品的機密源代碼
- 內部會議記錄
- 未公開的技術規格

**後果**:
- 這些資料被 OpenAI 用於模型訓練
- 可能被其他用戶的查詢觸發回應
- 三星緊急禁止員工使用公開 AI 工具

### Linux 類比: `chmod` 與權限意識

```bash
# 新手階段: 不理解為什麼需要權限控制
$ cat /var/log/secure
Permission denied

# 學習階段: 知道 chmod 777 能解決，但不理解風險
$ chmod 777 /var/log/secure
# 糟糕... 所有人都能讀敏感日誌

# 成熟階段: 理解權限是保護機制
$ chmod 600 sensitive.log  # 只有擁有者可讀寫
$ sudo chown app:app sensitive.log  # 設定正確的擁有者
```

**與 AI 分享數據亦然**:
- **新手**: 不知道什麼該保護，全部分享
- **學習**: 知道要保護，但不確定保護什麼
- **成熟**: 建立系統化的隱私保護工作流

---

## 三步驟隱私保護工作流

### Step 1: 識別 - 什麼是敏感資訊？

#### 敏感資訊分類清單

| 類別 | 範例 | 風險等級 | 是否可分享 |
|------|------|----------|------------|
| **憑證 & 密鑰** | API keys, passwords, tokens, SSL 憑證 | 🔴 極高 | ❌ 絕對不可 |
| **個人資料 (PII)** | 用戶姓名、email、電話、身分證號 | 🔴 極高 | ❌ 絕對不可 |
| **商業機密** | 未公開產品代碼、演算法、商業邏輯 | 🔴 極高 | ❌ 絕對不可 |
| **內部架構** | 伺服器 IP、內部服務名稱、資料庫架構 | 🟡 中等 | ⚠️ 需脫敏處理 |
| **測試數據** | 包含真實用戶資料的測試集 | 🟡 中等 | ⚠️ 需脫敏處理 |
| **公開代碼** | 開源專案、公開文檔 | 🟢 低 | ✅ 安全分享 |
| **錯誤訊息** | Stack trace (已清理敏感資訊) | 🟢 低 | ✅ 安全分享 |

#### 快速識別檢查表

**在分享代碼給 AI 前，掃描以下模式**:

```python
# 🔴 憑證類
- password =
- api_key =
- secret =
- token =
- private_key =
- AWS_ACCESS_KEY =

# 🔴 個人資料
- email = "real@example.com"
- phone = "0912-345-678"
- ssn =
- credit_card =

# 🟡 內部資訊
- db_host = "10.0.1.5"
- internal_api = "https://api.internal.company.com"
- COMPANY_SECRET_SALT =

# 🔴 商業機密
- PRICING_ALGORITHM =
- RECOMMENDATION_MODEL =
- 未公開的產品特性代碼
```

---

### Step 2: 清理 - 如何脫敏處理？

#### 清理技術 #1: 佔位符替換

```python
# ❌ 原始代碼 (包含敏感資訊)
import openai
openai.api_key = "sk-proj-abc123def456..."
db_url = "postgresql://admin:P@ssw0rd@10.0.1.5:5432/production"

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "分析銷售數據"}]
)

# ✅ 清理後的代碼 (可安全分享)
import openai
openai.api_key = os.getenv('OPENAI_API_KEY')  # 改為環境變數
db_url = os.getenv('DATABASE_URL')  # 隱藏連線字串

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "分析銷售數據"}]
)
```

#### 清理技術 #2: 數據合成化

```python
# ❌ 原始數據 (真實用戶資料)
users = [
    {"name": "王小明", "email": "xiaoming@gmail.com", "phone": "0912-345-678"},
    {"name": "李小華", "email": "xiaohua@yahoo.com", "phone": "0987-654-321"}
]

# ✅ 合成數據 (保持結構，替換真實資料)
users = [
    {"name": "User_A", "email": "user_a@example.com", "phone": "0900-000-001"},
    {"name": "User_B", "email": "user_b@example.com", "phone": "0900-000-002"}
]
```

#### 清理技術 #3: 架構通用化

```python
# ❌ 原始配置 (洩漏內部架構)
SERVICES = {
    "auth": "https://auth-prod.internal.company.com",
    "api": "https://api-v2.internal.company.com",
    "db_primary": "10.0.1.5",
    "db_replica": "10.0.1.6"
}

# ✅ 通用化配置 (保持結構，隱藏細節)
SERVICES = {
    "auth": "https://auth-service.example.com",
    "api": "https://api-service.example.com",
    "db_primary": "PRIMARY_DB_HOST",
    "db_replica": "REPLICA_DB_HOST"
}
```

#### 自動化清理工具

```bash
# 使用 sed 批量替換敏感資訊 (Linux/Mac)
sed -i 's/sk-proj-[a-zA-Z0-9]*/OPENAI_API_KEY/g' code.py
sed -i 's/[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}\.[0-9]\{1,3\}/REDACTED_IP/g' code.py

# 使用 Python 腳本自動清理
python scripts/sanitize_code.py input.py --output safe.py
```

---

### Step 3: 驗證 - 確認清理完整性

#### 驗證檢查清單

```
分享前最後檢查:

[ ] 1. 搜尋關鍵詞
    grep -E "(password|api_key|secret|token)" code.py

[ ] 2. 檢查長字串 (可能是 token)
    grep -E '[a-zA-Z0-9]{32,}' code.py

[ ] 3. 檢查 IP 地址
    grep -E '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' code.py

[ ] 4. 檢查 email
    grep -E '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' code.py

[ ] 5. 手動掃讀一遍
    問自己：這段代碼可以公開在 GitHub 嗎？
```

#### 驗證工具

```bash
# 使用 detect-secrets 掃描
pip install detect-secrets
detect-secrets scan code.py

# 使用 git-secrets (即使還沒 commit)
git secrets --scan code.py
```

---

## 合規考量

### GDPR (歐盟一般資料保護規則)

**核心原則**: 個人資料必須有合法處理依據

#### 分享代碼給 AI 的 GDPR 檢查

```
[ ] 代碼中是否包含歐盟公民的個人資料？
    → 是：必須脫敏或取得明確同意
    → 否：可以分享

[ ] 公司是否有數據處理協議 (DPA) 與 AI 服務提供商？
    → 是：確認協議涵蓋此用途
    → 否：諮詢法務部門

[ ] 是否使用企業版 AI 工具 (如 ChatGPT Enterprise)?
    → 是：數據不會用於訓練，風險較低
    → 否：數據可能被用於訓練，謹慎處理
```

### License 合規

**問題**: AI 生成的代碼可能包含有版權的片段

#### 合規檢查清單

```
[ ] 1. 檢查 AI 生成代碼的來源
    有些 AI 會標註代碼來源 (如 GitHub Copilot)

[ ] 2. 搜尋可疑片段
    將生成的代碼片段 Google 搜尋
    → 如果找到完全相同的開源代碼，檢查其 license

[ ] 3. 遵守 license 要求
    - MIT/BSD: 保留版權聲明
    - Apache 2.0: 保留版權聲明 + NOTICE 文件
    - GPL: 衍生作品必須開源
    - 專有軟體: 不可使用

[ ] 4. 公司政策確認
    有些公司禁止使用 AI 生成代碼
    → 確認公司 AI 使用政策
```

---

## 不同場景的隱私策略

### 場景 #1: 使用公開 AI 工具 (ChatGPT, Claude, Gemini)

**風險**: 數據可能用於模型訓練

**策略**:
1. ✅ 只分享公開資訊或完全脫敏的代碼
2. ✅ 使用合成數據代替真實數據
3. ✅ 隱藏所有內部架構細節
4. ❌ 絕不分享憑證、PII、商業機密

---

### 場景 #2: 使用企業版 AI 工具 (ChatGPT Enterprise, Claude for Work)

**風險**: 較低，數據通常不用於訓練，但仍有洩漏風險

**策略**:
1. ✅ 確認企業協議涵蓋數據保護
2. ✅ 可分享內部代碼結構 (但仍需脫敏憑證)
3. ⚠️ 謹慎分享商業機密 (取決於公司政策)
4. ❌ 仍不可分享憑證

---

### 場景 #3: 本地部署 AI 模型 (Ollama, LM Studio)

**風險**: 最低，數據不離開本地

**策略**:
1. ✅ 可分享內部代碼 (在合規前提下)
2. ✅ 可使用真實數據結構
3. ⚠️ 仍需確保憑證不被記錄到日誌
4. ✅ 適合處理高敏感性任務

---

## 實戰案例

### 案例 #1: Stack Overflow 問題發布

**情境**: 你想在 Stack Overflow 或 GitHub Issues 詢問問題

**錯誤做法** ❌:
```python
# 直接複製生產代碼
import boto3
client = boto3.client(
    's3',
    aws_access_key_id='AKIAIOSFODNN7EXAMPLE',
    aws_secret_access_key='wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'
)
```

**正確做法** ✅:
```python
# 清理後的最小化複現範例
import boto3
client = boto3.client(
    's3',
    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),
    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY')
)

# 問題: 為什麼 client.list_buckets() 返回 AccessDenied?
```

---

### 案例 #2: AI 代碼審查

**情境**: 你想讓 AI 審查一段認證邏輯

**錯誤做法** ❌:
```python
def authenticate(username, password):
    # 公司內部認證邏輯
    user = db.query(f"SELECT * FROM company_users WHERE username='{username}'")
    if user and bcrypt.checkpw(password, user.hashed_password):
        # 使用公司專有的 JWT 簽章演算法
        token = sign_jwt(user.id, SECRET_KEY="prod_secret_123")
        return token
```

**正確做法** ✅:
```python
def authenticate(username, password):
    # 通用化的認證邏輯
    user = db.query("SELECT * FROM users WHERE username=%s", (username,))
    if user and verify_password(password, user.hashed_password):
        token = create_token(user.id)
        return token

# 問題: 這個認證流程有安全漏洞嗎？
```

**清理要點**:
1. 表名通用化: `company_users` → `users`
2. 隱藏專有演算法: `sign_jwt()` → `create_token()`
3. 移除真實憑證: `SECRET_KEY="..."` → 移除

---

## 快速參考卡

### 分享代碼前 30 秒檢查法

```bash
# 1. 搜尋憑證 (5 秒)
grep -E "(password|api_key|secret|token)" file.py

# 2. 搜尋 IP 地址 (5 秒)
grep -E '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' file.py

# 3. 搜尋 email (5 秒)
grep -E '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' file.py

# 4. 自動掃描 (10 秒)
detect-secrets scan file.py

# 5. 人工檢視 (5 秒)
# 快速掃讀一遍，問自己：
# 「這可以公開在 Reddit 嗎？」
```

---

## 記憶口訣

> **「識清驗」- 識別、清理、驗證**

1. **識別**: 什麼是敏感資訊？
2. **清理**: 如何脫敏處理？
3. **驗證**: 確認清理完整性

---

## 學習驗證

完成本學習卡後，你應該能夠：

- [ ] 區分 5 種敏感資訊類型
- [ ] 使用至少 3 種清理技術脫敏代碼
- [ ] 在 30 秒內完成分享前檢查
- [ ] 理解 GDPR 與 License 的基本合規要求
- [ ] 根據不同場景選擇適當的隱私策略

---

## 下一步

1. **實作練習**: 使用「AI上下文清理指南」清理一段真實代碼
2. **工具設置**: 安裝 `detect-secrets` 並掃描你的專案
3. **深入學習**: 閱讀「理論/10.2_隱私與合規實踐.md」

---

**記住**：

> **「與 AI 分享代碼，就像在公共場所說話 — 不要說你不想被陌生人聽到的事」**

隱私保護不是一次性任務，而是每次互動的習慣。
