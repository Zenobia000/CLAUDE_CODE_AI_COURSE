# 6.2 多代理人編排實戰 - 從單打獨鬥到團隊協作

## 📚 本節概述

**學習時間**：60 分鐘（理論） + 90 分鐘（實作）

**學習目標**：
- 理解多代理人協作的核心概念
- 掌握四種工作流程編排模式
- 學會 Agent 切換的策略與時機
- 實作完整的自動化週報系統
- 建立錯誤處理與回退機制

**為什麼這很重要**：
> 單一 AI Agent 就像一個全能工程師，看似什麼都會，但什麼都不精。
> 多 Agent 編排就像一個專業團隊，每個人專注於自己的領域，協同完成複雜任務。

---

## 第一部分：多代理人協作的核心理念

### 1.1 從單一 Agent 到多 Agent 團隊

#### 單一 Agent 的局限性

**場景：生成一份技術文檔**

**單一 Agent 方式**：
```
User: "幫我生成一份 API 文檔"

Claude（通用 Agent）：
1. 分析程式碼結構
2. 提取 API 端點
3. 生成文檔
4. 檢查格式

結果：文檔生成了，但...
- 技術細節可能不夠深入（不是技術專家）
- 文檔風格可能不夠專業（不是文檔寫手）
- 程式碼範例可能有錯（沒有仔細驗證）
```

#### 多 Agent 團隊方式

**同樣場景，使用 Agent 團隊**：
```
User: "幫我生成一份 API 文檔"

協作流程：

1. 程式碼分析 Agent（code-analyzer）
   - 深入分析程式碼結構
   - 提取所有 API 端點
   - 識別參數與返回值
   - 輸出：結構化的 API 資料

2. 技術寫作 Agent（tech-writer）
   - 接收 API 資料
   - 用專業的技術寫作風格撰寫
   - 添加使用範例
   - 輸出：文檔草稿

3. 程式碼審查 Agent（code-reviewer）
   - 驗證程式碼範例是否正確
   - 檢查 API 描述是否準確
   - 提出改進建議
   - 輸出：審查報告

4. 文檔編輯 Agent（editor）
   - 修正技術寫作問題
   - 統一格式風格
   - 最終潤色
   - 輸出：完美的 API 文檔

結果：專業、準確、詳盡的技術文檔
```

**關鍵差異**：
| 單一 Agent | 多 Agent 團隊 |
|-----------|--------------|
| 通才，樣樣會一點 | 專家，各司其職 |
| 品質參差不齊 | 每個環節都專業 |
| 無法深入 | 可以深度專精 |
| 適合簡單任務 | 適合複雜專案 |

---

### 1.2 Agent 的角色定位

#### Claude Code 內建的 Agent Roles

```
通用 Agents：
- code-expert：程式碼專家（預設）
- architect：架構師（系統設計）
- reviewer：審查員（程式碼審查）
- debugger：除錯專家（問題診斷）

專業 Agents：
- security-auditor：安全審計員
- performance-optimizer：效能優化師
- test-engineer：測試工程師
- data-analyst：資料分析師
- tech-writer：技術文檔寫手
- devops-engineer：DevOps 工程師
```

#### 如何切換 Agent

```bash
# 方法 1：使用 /agents 指令
/agents:security-auditor

# 方法 2：在對話中明確指定
"請以安全審計員的角色分析這段程式碼"

# 方法 3：在工作流程中自動切換（後面會學）
```

---

### 1.3 Agent 切換的成本與收益

#### 切換成本

**時間成本**：
- 切換 Agent 需要重新載入上下文
- 每次切換約 5-10 秒

**上下文成本**：
- 新 Agent 需要理解先前的工作
- 可能需要重複說明需求

**認知成本**：
- 你需要知道何時切換
- 你需要知道切換到哪個 Agent

#### 切換收益

**品質提升**：
- 專業 Agent 的輸出品質更高
- 更深入的分析與建議

**效率提升**：
- 專業 Agent 完成任務更快
- 減少返工次數

**風險降低**：
- 安全審計 Agent 可以找出隱藏的安全問題
- 效能優化 Agent 可以避免效能瓶頸

#### 何時應該切換 Agent？

**決策樹**：
```
任務複雜度 < 簡單 ?
├─ 是 → 使用預設 Agent（code-expert）
└─ 否
    └─ 任務是否需要專業知識？
        ├─ 安全相關 → security-auditor
        ├─ 效能問題 → performance-optimizer
        ├─ 測試相關 → test-engineer
        ├─ 架構設計 → architect
        ├─ 程式碼審查 → reviewer
        └─ 資料分析 → data-analyst
```

**經驗法則**：
- **簡單任務**：不切換（成本 > 收益）
- **中等任務**：視情況切換（成本 ≈ 收益）
- **複雜任務**：一定要切換（成本 < 收益）

---

## 第二部分：四種工作流程編排模式

### 2.1 模式 1：串行（Sequential）

#### 定義

**任務按順序執行，每個任務完成後才執行下一個。**

#### 特點

```
Task 1 → Task 2 → Task 3 → Task 4 → 完成

優點：
- 簡單易懂
- 容易除錯
- 結果可預測

缺點：
- 總時間 = 所有任務時間總和
- 無法並行加速
- 某個任務失敗會阻塞整個流程
```

#### 適用場景

- 任務之間有依賴關係
- 後續任務需要前一個任務的輸出
- 順序很重要

#### 範例 1：程式碼審查流程

```
情境：審查一個 Pull Request

工作流程：
1. 程式碼分析 Agent（code-analyzer）
   - 分析程式碼結構
   - 識別修改的檔案
   - 提取關鍵變更
   輸出：程式碼分析報告

2. 安全審計 Agent（security-auditor）
   - 基於分析報告
   - 檢查安全漏洞
   - 識別危險模式
   輸出：安全審計報告

3. 效能優化 Agent（performance-optimizer）
   - 基於程式碼分析
   - 檢查效能問題
   - 提出優化建議
   輸出：效能分析報告

4. 審查總結 Agent（reviewer）
   - 整合所有報告
   - 給出最終建議
   - 生成 PR 評論
   輸出：PR Review 意見

特點：必須串行，因為每一步都依賴前一步的輸出
```

#### 實作方式

**方法 1：手動切換**
```
User: "分析這個 PR 的程式碼"
[等待完成]

User: "/agents:security-auditor，基於剛才的分析，檢查安全問題"
[等待完成]

User: "/agents:performance-optimizer，檢查效能問題"
[等待完成]

User: "/agents:reviewer，整合所有報告，給出最終建議"
[等待完成]
```

**方法 2：一次性指令**
```
User: "審查這個 PR，流程如下：
1. 分析程式碼結構（code-analyzer）
2. 安全審計（security-auditor）
3. 效能分析（performance-optimizer）
4. 生成最終建議（reviewer）
請依序完成所有步驟。"

Claude 會自動執行整個流程
```

---

### 2.2 模式 2：並行（Parallel）

#### 定義

**多個任務同時執行，所有任務完成後才進入下一階段。**

#### 特點

```
        ┌─ Task 1 ─┐
Start ──┼─ Task 2 ─┼─→ 完成
        └─ Task 3 ─┘

優點：
- 總時間 = 最慢任務的時間
- 大幅提升效率
- 適合獨立任務

缺點：
- 協調複雜度高
- 某個任務失敗影響全局
- 需要等待最慢的任務
```

#### 適用場景

- 任務之間沒有依賴關係
- 任務可以獨立執行
- 時間敏感，需要加速

#### 範例 2：多資料來源分析

```
情境：生成綜合報告

工作流程（並行）：

同時啟動三個 Agent：

1. GitHub Agent + GitHub MCP
   - 獲取 GitHub issues 資料
   - 分析 issue 趨勢
   - 提取關鍵問題

2. Database Agent + Database MCP
   - 查詢用戶數據
   - 計算關鍵指標
   - 生成統計圖表

3. Slack Agent + Slack MCP
   - 讀取團隊討論
   - 提取重要決策
   - 整理待辦事項

等待所有 Agent 完成後：

4. 報告整合 Agent（data-analyst）
   - 整合三個來源的資料
   - 生成綜合報告
   - 發現關聯與洞察

特點：3 個資料獲取任務可以並行，節省 2/3 的時間
```

#### 實作方式

**Claude Code 的並行支援**：
```
User: "同時執行以下任務：
1. 從 GitHub MCP 獲取 issues（data-analyst）
2. 從 Database MCP 查詢用戶數據（data-analyst）
3. 從 Slack MCP 讀取團隊討論（data-analyst）

等所有任務完成後，整合成綜合報告。"

Claude 會自動並行執行
```

---

### 2.3 模式 3：條件分支（Conditional）

#### 定義

**根據條件決定執行哪條路徑。**

#### 特點

```
Start → 條件判斷
         ├─ 條件 A → Task A1 → Task A2
         ├─ 條件 B → Task B1 → Task B2
         └─ 條件 C → Task C1

優點：
- 靈活應對不同情況
- 避免不必要的任務
- 智能決策

缺點：
- 流程複雜度高
- 需要清晰的條件定義
- 難以除錯
```

#### 適用場景

- 不同情況需要不同處理
- 需要智能決策
- 資源有限，需要優先級

#### 範例 3：智能 Bug 分析

```
情境：用戶回報一個 Bug

工作流程：

1. Bug 分類 Agent（debugger）
   - 分析 Bug 描述
   - 識別 Bug 類型
   輸出：Bug 類型

2. 條件判斷：

   if Bug 類型 == "安全問題":
       → 安全審計 Agent（security-auditor）
       → 立即修復
       → 通知團隊

   elif Bug 類型 == "效能問題":
       → 效能分析 Agent（performance-optimizer）
       → 效能測試
       → 優化建議

   elif Bug 類型 == "邏輯錯誤":
       → 程式碼分析 Agent（code-analyzer）
       → 單元測試
       → 修復程式碼

   else:
       → 通用除錯 Agent（debugger）
       → 診斷問題
       → 提供解決方案

3. 後續處理（所有路徑匯合）
   - 生成 Bug 報告
   - 更新 Issue
   - 記錄到 Notion

特點：不同類型的 Bug 有不同的處理流程
```

#### 實作方式

```
User: "分析這個 Bug，根據類型選擇處理方式：
- 安全問題 → 安全審計流程
- 效能問題 → 效能分析流程
- 邏輯錯誤 → 程式碼分析流程
- 其他 → 通用除錯流程

執行對應流程並生成報告。"

Claude 會自動判斷並選擇路徑
```

---

### 2.4 模式 4：循環（Loop）

#### 定義

**重複執行某個任務，直到滿足退出條件。**

#### 特點

```
Start → Task → 檢查條件
                ├─ 未達成 → 回到 Task
                └─ 達成 → 完成

優點：
- 適合迭代優化
- 可以持續改進
- 自動化重複工作

缺點：
- 可能無限循環
- 需要清晰的退出條件
- 時間不可預測
```

#### 適用場景

- 需要迭代優化
- 需要達到特定品質標準
- 自動化重複任務

#### 範例 4：程式碼品質迭代

```
情境：優化程式碼直到達到品質標準

工作流程：

循環開始：

1. 程式碼分析 Agent（code-analyzer）
   - 分析程式碼品質
   - 計算品質分數
   輸出：品質分數

2. 檢查條件：
   if 品質分數 >= 90:
       → 退出循環，完成優化
   else:
       → 繼續優化

3. 優化 Agent（performance-optimizer + security-auditor）
   - 識別最大的問題
   - 生成優化建議
   - 應用優化

4. 回到步驟 1（重新分析）

循環結束：
- 生成優化報告
- 列出所有改進
- 最終品質分數

特點：持續優化直到達標
```

#### 實作方式

```
User: "優化這段程式碼，流程如下：
1. 分析品質分數（code-analyzer）
2. 如果分數 < 90，進行優化（performance-optimizer）
3. 重複步驟 1-2，直到分數 >= 90
4. 生成最終報告

最多迭代 5 次（避免無限循環）"

Claude 會自動執行迭代循環
```

---

### 2.5 模式組合：混合編排

#### 真實世界的複雜流程

**大多數真實場景都是多種模式的組合。**

#### 範例 5：企業級自動化測試流程

```
情境：完整的自動化測試與部署

工作流程（混合模式）：

階段 1：並行測試（Parallel）
┌─ 單元測試 Agent → 測試結果 1 ┐
├─ 整合測試 Agent → 測試結果 2 ┼→ 收集結果
└─ 效能測試 Agent → 測試結果 3 ┘

階段 2：條件判斷（Conditional）
if 所有測試通過:
    → 進入部署流程
else:
    → 通知開發者，終止流程

階段 3：串行部署（Sequential）
1. 建置 Agent → 建置完成
2. 部署到 Staging Agent → 部署完成
3. 驗證 Agent → 驗證結果
4. 部署到 Production Agent → 完成

階段 4：循環監控（Loop）
while 部署後 24 小時:
    1. 監控 Agent → 檢查健康狀態
    2. 如果異常 → 警報並回滾
    3. 等待 1 小時
    4. 繼續監控

特點：組合了所有四種模式
```

---

## 第三部分：實戰案例 1 - 自動化週報系統

### 3.1 需求分析

#### 痛點

**手動週報流程**（每週浪費 2 小時）：
1. 登入 GitHub，複製 issues 資料
2. 登入 Database，導出數據
3. 整理成週報格式
4. 手動發送到 Slack
5. 手動儲存到 Notion

#### 目標

**自動化週報流程**（一鍵執行，10 分鐘完成）：
- 自動從 GitHub 獲取 issues 資料
- 自動從 Database 查詢關鍵指標
- 自動生成週報
- 自動發送到 Slack
- 自動儲存到 Notion

---

### 3.2 系統架構

#### 涉及的 MCP Servers

```
1. GitHub MCP
   - 獲取本週關閉的 issues
   - 獲取本週合併的 PRs
   - 獲取 commits 統計

2. Database MCP（PostgreSQL）
   - 查詢用戶活躍度
   - 查詢系統效能指標
   - 查詢關鍵業務指標

3. Slack MCP
   - 發送週報到 #engineering channel
   - 發送摘要到 #management channel

4. Notion MCP
   - 儲存完整週報
   - 建立週報頁面
   - 歸檔到週報 database
```

#### 涉及的 AI Agents

```
1. Data Analyst Agent（data-analyst）
   - 分析 GitHub 資料
   - 分析 Database 資料
   - 計算趨勢與洞察

2. Report Writer Agent（tech-writer）
   - 生成週報文案
   - 格式化資料
   - 撰寫摘要與建議

3. Communication Agent（code-expert）
   - 發送 Slack 訊息
   - 儲存 Notion 頁面
   - 確認發送成功
```

---

### 3.3 工作流程設計

#### 完整流程（混合編排）

```
階段 1：資料獲取（並行）Parallel
┌─ Task 1.1：GitHub 資料獲取
│   Agent: data-analyst
│   MCP: GitHub MCP
│   操作：
│   - 獲取本週關閉的 issues
│   - 獲取本週合併的 PRs
│   - 獲取 commits 統計
│   輸出：GitHub 資料包
│
├─ Task 1.2：Database 資料獲取
│   Agent: data-analyst
│   MCP: Database MCP
│   操作：
│   - 查詢本週用戶活躍度
│   - 查詢系統效能指標
│   - 查詢關鍵業務指標
│   輸出：Database 資料包
│
等待所有任務完成...

階段 2：資料分析（串行）Sequential
Task 2.1：整合資料
   Agent: data-analyst
   輸入：GitHub 資料包 + Database 資料包
   操作：
   - 整合所有資料
   - 計算關鍵指標
   - 發現趨勢與異常
   輸出：分析報告

Task 2.2：生成週報
   Agent: tech-writer
   輸入：分析報告
   操作：
   - 撰寫週報文案
   - 格式化圖表
   - 添加摘要與建議
   輸出：週報文檔（Markdown）

階段 3：分發週報（並行）Parallel
┌─ Task 3.1：發送到 Slack
│   Agent: code-expert
│   MCP: Slack MCP
│   操作：
│   - 發送完整版到 #engineering
│   - 發送摘要版到 #management
│   輸出：Slack 訊息連結
│
├─ Task 3.2：儲存到 Notion
│   Agent: code-expert
│   MCP: Notion MCP
│   操作：
│   - 建立週報頁面
│   - 填入週報內容
│   - 歸檔到週報 database
│   輸出：Notion 頁面連結
│
等待所有任務完成...

階段 4：確認與通知（串行）Sequential
Task 4.1：確認成功
   Agent: code-expert
   操作：
   - 確認 Slack 發送成功
   - 確認 Notion 儲存成功
   - 生成執行日誌
   輸出：執行報告

Task 4.2：通知完成
   輸出：
   - Slack 連結：https://...
   - Notion 連結：https://...
   - 執行時間：8 分鐘
   - 週報已完成！
```

---

### 3.4 實作步驟

#### Step 1：配置所有 MCP Servers

```json
// .claude/mcp-config.json
{
  "mcpServers": {
    "github": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-github"],
      "env": {
        "GITHUB_TOKEN": "ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      }
    },
    "postgres": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-postgres"],
      "env": {
        "POSTGRES_CONNECTION_STRING": "postgresql://readonly:password@localhost:5432/analytics"
      }
    },
    "slack": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-slack"],
      "env": {
        "SLACK_BOT_TOKEN": "xoxb-your-bot-token",
        "SLACK_TEAM_ID": "T01234567"
      }
    },
    "notion": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-notion"],
      "env": {
        "NOTION_API_KEY": "secret_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
      }
    }
  }
}
```

#### Step 2：定義週報範本

```markdown
# 工程週報 - {日期範圍}

## 📊 本週數據總覽

### GitHub 活動
- 關閉 Issues：{count}
- 合併 PRs：{count}
- 新增 Commits：{count}
- 活躍貢獻者：{count}

### 用戶指標
- 活躍用戶數：{count}（週增長：{percent}%）
- 新註冊用戶：{count}
- 用戶留存率：{percent}%

### 系統效能
- 平均回應時間：{ms}ms
- 錯誤率：{percent}%
- 系統正常運行時間：{percent}%

## 🎯 本週重點

### 已完成
- {Issue 標題}（#{issue_number}）
- {Issue 標題}（#{issue_number}）

### 進行中
- {Issue 標題}（#{issue_number}）
- {Issue 標題}（#{issue_number}）

## 📈 趨勢分析

{AI 生成的趨勢洞察}

## ⚠️ 需要關注

{AI 識別的風險與建議}

## 📝 下週計畫

{基於當前進度的下週建議}

---
*本週報由 AI 自動生成 • {生成時間}*
```

#### Step 3：編寫自動化指令

**方式 A：互動式執行**
```
User: "生成本週週報，流程如下：

階段 1（並行）：
1. 從 GitHub MCP 獲取本週資料（data-analyst）
2. 從 Database MCP 查詢關鍵指標（data-analyst）

階段 2（串行）：
3. 整合資料並分析（data-analyst）
4. 生成週報文檔（tech-writer）

階段 3（並行）：
5. 發送到 Slack #engineering（code-expert）
6. 儲存到 Notion 週報 database（code-expert）

階段 4：
7. 確認完成並提供連結

開始執行！"
```

**方式 B：腳本化（進階）**
```bash
# weekly-report.sh
#!/bin/bash

echo "🚀 開始生成週報..."

# 調用 Claude Code 執行流程
claude << EOF
生成本週週報，使用預定義流程。

配置：
- GitHub repo: myorg/myproject
- Database: analytics
- Slack channels: #engineering, #management
- Notion database: 週報資料庫

執行完整流程並提供結果連結。
EOF

echo "✅ 週報生成完成！"
```

#### Step 4：執行與驗證

**預期執行時間**：8-10 分鐘

**執行流程觀察**：
```
[00:00] 開始執行...
[00:15] 並行獲取資料中...
[02:30] GitHub 資料獲取完成 ✓
[02:45] Database 資料獲取完成 ✓
[03:00] 開始資料分析...
[04:30] 分析完成，生成週報文檔...
[06:00] 週報文檔生成完成 ✓
[06:15] 並行分發中...
[07:30] Slack 發送完成 ✓
[07:45] Notion 儲存完成 ✓
[08:00] 執行完成！

結果：
- Slack：https://slack.com/archives/C123456/p1234567890
- Notion：https://notion.so/週報-2025-10-30
- 執行時間：8 分鐘
```

---

### 3.5 錯誤處理與回退機制

#### 常見錯誤與處理

**錯誤 1：GitHub MCP 調用失敗**

**症狀**：
```
Error: GitHub API rate limit exceeded
```

**回退方案**：
```
1. 檢測到 rate limit 錯誤
2. 等待 60 秒後重試
3. 如果仍失敗，使用快取的資料
4. 在週報中標註「使用快取資料」
5. 通知管理員檢查 API quota
```

**實作**：
```
User: "生成週報，如果 GitHub API rate limit，
      使用快取資料並標註。"

Claude 會自動處理錯誤並回退
```

---

**錯誤 2：Database 查詢超時**

**症狀**：
```
Error: Query timeout after 30s
```

**回退方案**：
```
1. 檢測到超時
2. 取消當前查詢
3. 使用簡化查詢（只查核心指標）
4. 在週報中標註「使用簡化資料」
5. 記錄錯誤，後續優化查詢
```

---

**錯誤 3：Slack 發送失敗**

**症狀**：
```
Error: Channel not found
```

**回退方案**：
```
1. 檢測到 channel 錯誤
2. 嘗試發送到備用 channel（如 #general）
3. 如果仍失敗，儲存為本地檔案
4. 通知管理員手動處理
5. 記錄錯誤以供修正
```

---

#### 完整錯誤處理策略

```
錯誤等級分類：

Level 1：可恢復錯誤（Recoverable）
- Rate limit → 等待重試
- 網路暫時中斷 → 重試 3 次
- 資料暫時不可用 → 使用快取

Level 2：可降級錯誤（Degradable）
- 非關鍵資料缺失 → 標註並繼續
- 部分功能失敗 → 使用替代方案
- 效能問題 → 使用簡化流程

Level 3：致命錯誤（Fatal）
- 認證失敗 → 立即停止，通知管理員
- 所有 MCP 都失敗 → 終止流程
- 關鍵資料完全缺失 → 無法生成週報

錯誤處理流程：
1. 捕獲錯誤
2. 判斷錯誤等級
3. 執行對應策略
4. 記錄錯誤日誌
5. 通知相關人員（如果需要）
```

---

## 第四部分：實戰案例 2 - 知識萃取系統

### 4.1 系統概述

**目標**：從網路文章自動萃取知識，整理成 Notion 頁面，並生成 Anki 記憶卡。

**涉及的 MCP Servers**：
- Web Scraping MCP（抓取網頁內容）
- Notion MCP（儲存知識頁面）
- File System MCP（生成 Anki 記憶卡檔案）

**涉及的 AI Agents**：
- Content Analyzer（內容分析）
- Knowledge Extractor（知識萃取）
- Flashcard Generator（記憶卡生成）

---

### 4.2 工作流程設計

```
輸入：文章 URL 列表

階段 1：批次抓取（並行）Parallel
對每個 URL：
  ├─ Web Scraping MCP → 抓取內容
  └─ 解析成 Markdown

等待所有抓取完成...

階段 2：內容分析（串行）Sequential
Task 2.1：內容分類
   Agent: Content Analyzer
   操作：
   - 識別文章類型（技術、理論、實戰）
   - 提取關鍵主題
   - 評估重要性
   輸出：文章分類與主題

Task 2.2：知識萃取
   Agent: Knowledge Extractor
   操作：
   - 提取核心概念
   - 識別關鍵論點
   - 整理為結構化筆記
   輸出：結構化知識

階段 3：多輸出生成（並行）Parallel
┌─ Task 3.1：生成 Notion 頁面
│   Agent: Knowledge Extractor
│   MCP: Notion MCP
│   操作：
│   - 建立知識頁面
│   - 填入結構化內容
│   - 添加標籤與連結
│   輸出：Notion 頁面連結
│
├─ Task 3.2：生成 Anki 記憶卡
│   Agent: Flashcard Generator
│   MCP: File System MCP
│   操作：
│   - 從知識中提取 Q&A
│   - 生成 Anki 格式檔案
│   - 儲存為 .apkg
│   輸出：Anki 記憶卡檔案
│
等待所有任務完成...

階段 4：建立知識圖譜（條件）Conditional
if 相關主題存在:
    ├─ 連結到現有頁面
    ├─ 更新知識圖譜
    └─ 標註關聯性
else:
    └─ 建立新的知識節點

輸出：
- Notion 頁面：https://notion.so/...
- Anki 卡片：knowledge_cards.apkg
- 知識圖譜已更新
```

---

### 4.3 實作細節

#### Notion 頁面範本

```markdown
# {文章標題}

## 📝 元資訊
- 來源：{URL}
- 作者：{作者}
- 日期：{日期}
- 分類：{分類標籤}
- 重要性：⭐⭐⭐⭐☆

## 💡 核心概念

### 概念 1：{概念名稱}
{定義}

**關鍵點**：
- {要點 1}
- {要點 2}

### 概念 2：{概念名稱}
{定義}

## 🎯 主要論點

1. {論點 1}
   - 支持論據：{論據}
   - 實例：{實例}

2. {論點 2}
   - 支持論據：{論據}
   - 實例：{實例}

## 💻 實作範例

```code
{程式碼範例}
```

**說明**：{範例說明}

## 🔗 相關主題
- [[相關主題 1]]
- [[相關主題 2]]

## 🤔 個人思考

{AI 生成的思考與連結}

## 📚 延伸閱讀
- {相關文章 1}
- {相關文章 2}

---
*由 AI 自動萃取 • {萃取時間}*
```

#### Anki 記憶卡生成

**卡片類型 1：概念定義**
```
Q: 【概念】什麼是 {概念名稱}？

A: 【定義】{定義}

   【關鍵點】
   - {要點 1}
   - {要點 2}

   【來源】{文章標題}
```

**卡片類型 2：情境應用**
```
Q: 【情境】在什麼情況下應該使用 {概念}？

A: 【適用場景】
   - 場景 1：{描述}
   - 場景 2：{描述}

   【注意事項】{注意事項}

   【來源】{文章標題}
```

**卡片類型 3：對比辨析**
```
Q: 【對比】{概念 A} 和 {概念 B} 的差異是什麼？

A: 【差異分析】
   | 特性 | {概念 A} | {概念 B} |
   |-----|---------|---------|
   | {特性 1} | {A 的特點} | {B 的特點} |
   | {特性 2} | {A 的特點} | {B 的特點} |

   【來源】{文章標題}
```

---

## 第五部分：AI Agent 與 MCP 的配合使用

### 5.1 Agent 的 MCP 調用策略

#### 原則 1：Agent 選擇適合的 MCP

**不同 Agent 對 MCP 的偏好**：

```
Data Analyst Agent：
  優先使用：
  - Database MCP（資料查詢）
  - GitHub MCP（程式碼數據）
  - File System MCP（本地資料）

Security Auditor Agent：
  優先使用：
  - GitHub MCP（程式碼掃描）
  - Database MCP（權限檢查）
  - File System MCP（配置檢查）

Tech Writer Agent：
  優先使用：
  - Notion MCP（文檔儲存）
  - File System MCP（檔案生成）
  - Slack MCP（文檔分享）

DevOps Engineer Agent：
  優先使用：
  - GitHub MCP（CI/CD）
  - Database MCP（部署腳本）
  - Slack MCP（部署通知）
```

**Claude 會自動選擇適合的 MCP**。

---

#### 原則 2：Agent 狀態持續性

**問題**：切換 Agent 後，前一個 Agent 的上下文會丟失嗎？

**答案**：不會！Claude Code 會維護完整的對話歷史。

**範例**：
```
User: "從 GitHub 獲取 issues"
[切換到 data-analyst]
Claude: 已獲取 50 個 issues

User: "/agents:security-auditor，分析剛才的 issues 有沒有安全問題"
[切換到 security-auditor]
Claude: 分析剛才獲取的 50 個 issues...
       發現 3 個安全相關的 issues

關鍵：Claude 還記得「剛才的 issues」
```

---

#### 原則 3：Agent 與 MCP 的權限管理

**問題**：不同 Agent 應該有不同的 MCP 權限嗎？

**目前狀態**：所有 Agent 共享相同的 MCP 配置。

**最佳實踐**：
- 在 MCP 層面做權限控制（如只給 SELECT 權限）
- 不依賴 Agent 層面的權限隔離
- 敏感操作需要人工確認

**範例**：
```json
// Database MCP 配置：只給唯讀權限
{
  "mcpServers": {
    "postgres": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-postgres"],
      "env": {
        "POSTGRES_CONNECTION_STRING": "postgresql://readonly:password@localhost:5432/analytics"
      }
    }
  }
}

// 這樣即使是任何 Agent，也只能查詢，不能修改資料
```

---

## 第六部分：進階技巧與最佳實踐

### 6.1 工作流程設計原則

#### 原則 1：優先使用簡單模式

```
能用串行就不用並行
能用並行就不用條件分支
能用條件分支就不用循環

原因：
- 簡單模式更容易理解
- 簡單模式更容易除錯
- 簡單模式更容易維護
```

#### 原則 2：明確的任務邊界

```
好的任務劃分：
✓ Task 1：從 GitHub 獲取 issues
✓ Task 2：分析 issues 資料
✓ Task 3：生成報告

壞的任務劃分：
✗ Task 1：獲取並分析 issues，然後生成報告

原因：邊界不清晰，難以重用和除錯
```

#### 原則 3：可觀測性

```
每個任務應該：
- 有明確的輸入
- 有明確的輸出
- 有執行時間記錄
- 有成功/失敗狀態

範例：
Task: 獲取 GitHub issues
輸入：repo="myorg/myproject", state="open"
輸出：50 個 issues
時間：2.3 秒
狀態：成功 ✓
```

#### 原則 4：冪等性

```
重複執行相同的工作流程，應該得到相同的結果。

好的設計：
✓ 生成週報（每次都基於最新資料）
✓ 分析程式碼（結果一致）

壞的設計：
✗ 「新增」issue（重複執行會創建多個）
✗ 「發送」通知（重複執行會發送多次）

解決方案：加入檢查機制
- 檢查 issue 是否已存在
- 檢查通知是否已發送
```

---

### 6.2 效能優化技巧

#### 技巧 1：並行化獨立任務

**慢**：
```
時間 = Task1 + Task2 + Task3
     = 3s + 3s + 3s = 9s
```

**快**：
```
時間 = max(Task1, Task2, Task3)
     = max(3s, 3s, 3s) = 3s
節省：6s（66% 時間節省）
```

#### 技巧 2：快取中間結果

**慢**：
```
每次生成週報都重新獲取所有資料
時間：8 分鐘
```

**快**：
```
快取最近 5 分鐘內獲取的資料
時間：2 分鐘（如果資料在快取中）
節省：6 分鐘（75% 時間節省）
```

#### 技巧 3：延遲載入

**慢**：
```
一次載入所有資料（包括可能不需要的）
時間：10 分鐘
```

**快**：
```
先載入必要資料，按需載入其他資料
時間：4 分鐘（如果不需要額外資料）
節省：6 分鐘（60% 時間節省）
```

---

### 6.3 可靠性增強技巧

#### 技巧 1：重試機制

```python
# 偽代碼
def call_mcp_with_retry(mcp_call, max_retries=3):
    for attempt in range(max_retries):
        try:
            return mcp_call()
        except TransientError as e:
            if attempt < max_retries - 1:
                wait(2 ** attempt)  # Exponential backoff
                continue
            else:
                raise
```

**範例**：
```
User: "獲取 GitHub issues，如果失敗，重試 3 次，
      每次等待時間加倍（2s, 4s, 8s）"

Claude 會自動實作重試機制
```

#### 技巧 2：健康檢查

```
工作流程開始前：
1. 檢查所有 MCP 是否可用
2. 檢查 API keys 是否有效
3. 檢查網路連線

如果檢查失敗：
- 立即停止
- 提供明確的錯誤訊息
- 提供修復建議
```

#### 技巧 3：降級方案

```
正常流程：
  獲取即時資料 → 生成報告

降級流程（如果即時資料不可用）：
  使用快取資料 → 生成報告（標註使用快取）

終極降級（如果快取也不可用）：
  使用預設範本 → 生成基礎報告
```

---

## 本節總結

### 核心概念回顧

**多代理人協作**：
- 專家團隊 > 全能個人
- 每個 Agent 專注於自己的領域
- 協同完成複雜任務

**四種編排模式**：
| 模式 | 特點 | 適用場景 |
|-----|------|---------|
| 串行 | 順序執行 | 任務有依賴關係 |
| 並行 | 同時執行 | 任務獨立，需要加速 |
| 條件分支 | 根據條件選擇路徑 | 需要智能決策 |
| 循環 | 重複執行直到達標 | 迭代優化 |

**Agent 與 MCP 配合**：
- Agent 選擇適合的 MCP
- Agent 狀態在切換後依然保留
- MCP 層面做權限控制

**最佳實踐**：
1. 優先使用簡單模式
2. 明確任務邊界
3. 確保可觀測性
4. 設計冪等操作
5. 並行化獨立任務
6. 實作重試與降級

---

### 實踐檢查點

完成以下檢查點，確保你已掌握多代理人編排：

**基礎級**：
- [ ] 理解四種編排模式的差異
- [ ] 能說明何時應該切換 Agent
- [ ] 能設計簡單的串行工作流程
- [ ] 理解 Agent 與 MCP 的關係

**中級**：
- [ ] 能設計 2-MCP 協同的並行工作流程
- [ ] 能實作基本的錯誤處理
- [ ] 能使用條件分支處理不同情況
- [ ] 能優化工作流程的執行時間

**進階**：
- [ ] 能設計 4+ MCP 協同的複雜工作流程
- [ ] 能實作完整的重試與降級機制
- [ ] 能組合多種編排模式
- [ ] 能為企業設計自動化平台

---

### 下一步

**立即實踐**：
1. 完成 `情境題庫/組合級/C01_自動化週報生成系統.md`
2. 實作完整的自動化週報系統
3. 體驗 4-MCP 協同的威力

**深入探索**：
1. 嘗試 `情境題庫/組合級/C02_知識萃取系統.md`
2. 學習 `實作/練習2_自訂MCP開發/`
3. 挑戰 `情境題庫/複雜級/E01_企業級DevOps自動化平台.md`

**記住**：
> 工作流程編排不是堆砌技術，而是解決實際問題。
> 從最小可行流程開始，逐步優化，持續改進。

現在你已經掌握了 MCP 協議與多代理人編排的核心知識，是時候去實戰了！🚀
