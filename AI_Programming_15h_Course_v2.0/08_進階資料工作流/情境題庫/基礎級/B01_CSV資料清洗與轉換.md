# B01ï¼šCSV è³‡æ–™æ¸…æ´—èˆ‡è½‰æ›

## ğŸ“‹ æƒ…å¢ƒæè¿°

### èƒŒæ™¯

ä½ æ˜¯ä¸€å®¶é›»å•†å…¬å¸çš„è³‡æ–™åˆ†æå¸«ã€‚å…¬å¸æ¯å¤©æ”¶åˆ°ä¾›æ‡‰å•†æä¾›çš„éŠ·å”®è³‡æ–™ CSV æª”æ¡ˆï¼Œä½†è³‡æ–™å“è³ªä¸ä½³ï¼Œéœ€è¦æ¸…æ´—å¾Œæ‰èƒ½è¼‰å…¥è³‡æ–™åº«é€²è¡Œåˆ†æã€‚

**å•é¡Œ**ï¼š
- æ—¥æœŸæ ¼å¼ä¸çµ±ä¸€ï¼ˆ`2025-01-30`, `30/01/2025`, `01-30-2025`ï¼‰
- é‡‘é¡æ¬„ä½æœ‰ç©ºå€¼
- ç”¢å“åç¨±æœ‰å¤šé¤˜çš„ç©ºæ ¼
- å­˜åœ¨é‡è¤‡è¨˜éŒ„
- éƒ¨åˆ†æ¬„ä½å‹åˆ¥éŒ¯èª¤

**ç›®å‰ç‹€æ³**ï¼š
- æ‰‹å‹•æ¸…æ´—éœ€è¦ 1 å°æ™‚
- å®¹æ˜“å‡ºéŒ¯ï¼Œéœ€è¦åè¦†æª¢æŸ¥
- ç„¡æ³•è‡ªå‹•åŒ–

### ç›®æ¨™

ç”¨ AI è¼”åŠ©å»ºç«‹è‡ªå‹•åŒ–æ¸…æ´—æµç¨‹ï¼Œ5 åˆ†é˜å…§å®Œæˆæ¸…æ´—ä½œæ¥­ã€‚

---

## ğŸ¯ ä»»å‹™ç›®æ¨™

### ä¸»è¦ä»»å‹™

1. **è³‡æ–™å“è³ªåˆ†æ**ï¼ˆ5 åˆ†é˜ï¼‰
   - è¼‰å…¥ CSV æª”æ¡ˆ
   - åˆ†æè³‡æ–™å•é¡Œï¼ˆç©ºå€¼ã€æ ¼å¼ã€ç•°å¸¸å€¼ï¼‰
   - ç”Ÿæˆå“è³ªå ±å‘Š

2. **è¨­è¨ˆæ¸…æ´—é‚è¼¯**ï¼ˆ10 åˆ†é˜ï¼‰
   - æ—¥æœŸæ ¼å¼æ¨™æº–åŒ–
   - è™•ç†ç©ºå€¼
   - æ¸…ç†å­—ä¸²
   - ç§»é™¤é‡è¤‡è¨˜éŒ„

3. **å¯¦ç¾æ¸…æ´—è…³æœ¬**ï¼ˆ10 åˆ†é˜ï¼‰
   - ç”¨ AI ç”Ÿæˆæ¸…æ´—ä»£ç¢¼
   - åŠ å…¥éŒ¯èª¤è™•ç†
   - åŠ å…¥æ—¥èªŒè¨˜éŒ„

4. **é©—è­‰çµæœ**ï¼ˆ5 åˆ†é˜ï¼‰
   - æª¢æŸ¥æ¸…æ´—å¾Œçš„è³‡æ–™å“è³ª
   - å°æ¯”æ¸…æ´—å‰å¾Œ
   - ç¢ºèªæ²’æœ‰éºæ¼

**ç¸½æ™‚é–“**ï¼š30 åˆ†é˜

---

## ğŸ“‚ æº–å‚™å·¥ä½œ

### æ¸¬è©¦è³‡æ–™

**`dirty_sales_data.csv`**ï¼ˆç¯„ä¾‹ï¼‰ï¼š
```csv
date,product_name,category,amount,region
2025-01-30,  iPhone 15  Pro ,Electronics,1299.99,North
30/01/2025,Samsung  Galaxy,Electronics,,South
01-30-2025,MacBook Pro,Electronics,2499.99,East
2025-01-30,iPhone 15 Pro,Electronics,1299.99,North
2025-01-31,iPad Air  ,Electronics,799.99,West
invalid_date,Dell XPS,Electronics,1599.99,North
2025-02-01,  iPhone 15  Pro ,Electronics,1299.99,South
```

**è³‡æ–™å•é¡Œ**ï¼š
1. æ—¥æœŸæ ¼å¼ä¸çµ±ä¸€ï¼ˆ3 ç¨®æ ¼å¼ï¼‰
2. `amount` æ¬„ä½æœ‰ç©ºå€¼ï¼ˆç¬¬ 3 è¡Œï¼‰
3. `product_name` æœ‰å¤šé¤˜ç©ºæ ¼
4. ç¬¬ 1 è¡Œå’Œç¬¬ 4 è¡Œæ˜¯é‡è¤‡è¨˜éŒ„
5. ç¬¬ 6 è¡Œæ—¥æœŸç„¡æ•ˆ

---

## ğŸš€ å¯¦ä½œæ­¥é©Ÿ

### æ­¥é©Ÿ 1ï¼šèˆ‡ AI å°è©±ï¼Œåˆ†æè³‡æ–™

**èˆ‡ Claude Code å°è©±**ï¼š
```
æˆ‘æœ‰ä¸€å€‹é«’äº‚çš„ CSV æª”æ¡ˆ dirty_sales_data.csvï¼Œè«‹å¹«æˆ‘ï¼š
1. è®€å–æª”æ¡ˆ
2. é¡¯ç¤ºå‰ 10 è¡Œ
3. åˆ†æè³‡æ–™å“è³ªå•é¡Œ
4. ç”Ÿæˆå“è³ªå ±å‘Š
```

**AI ç”Ÿæˆçš„ä»£ç¢¼**ï¼š
```python
import pandas as pd
import numpy as np

# Load data
df = pd.read_csv('dirty_sales_data.csv')

print("=" * 50)
print("Data Quality Report")
print("=" * 50)

# Basic info
print(f"\n1. Basic Information:")
print(f"   - Total rows: {len(df)}")
print(f"   - Total columns: {len(df.columns)}")
print(f"   - Columns: {list(df.columns)}")

# Data preview
print(f"\n2. Data Preview:")
print(df.head(10))

# Missing values
print(f"\n3. Missing Values:")
missing = df.isnull().sum()
if missing.sum() == 0:
    print("   âœ… No missing values")
else:
    for col, count in missing[missing > 0].items():
        pct = count / len(df) * 100
        print(f"   - {col}: {count} ({pct:.1f}%)")

# Data types
print(f"\n4. Data Types:")
print(df.dtypes)

# Duplicates
dup_count = df.duplicated().sum()
print(f"\n5. Duplicate Records: {dup_count}")

# String issues (extra spaces)
print(f"\n6. String Issues:")
for col in df.select_dtypes(include=['object']).columns:
    has_spaces = df[col].str.contains(r'^\s+|\s+$', na=False).sum()
    if has_spaces > 0:
        print(f"   - {col}: {has_spaces} records with leading/trailing spaces")

print("\n" + "=" * 50)
```

**è¼¸å‡ºç¯„ä¾‹**ï¼š
```
==================================================
Data Quality Report
==================================================

1. Basic Information:
   - Total rows: 7
   - Total columns: 5
   - Columns: ['date', 'product_name', 'category', 'amount', 'region']

2. Data Preview:
           date      product_name      category   amount region
0  2025-01-30    iPhone 15  Pro   Electronics  1299.99  North
1  30/01/2025   Samsung  Galaxy   Electronics      NaN  South
2  01-30-2025      MacBook Pro    Electronics  2499.99   East
3  2025-01-30    iPhone 15 Pro    Electronics  1299.99  North
4  2025-01-31        iPad Air     Electronics   799.99   West
5  invalid_date        Dell XPS    Electronics  1599.99  North
6  2025-02-01   iPhone 15  Pro   Electronics  1299.99  South

3. Missing Values:
   - amount: 1 (14.3%)

4. Data Types:
date             object
product_name     object
category         object
amount          float64
region           object

5. Duplicate Records: 1

6. String Issues:
   - product_name: 4 records with leading/trailing spaces

==================================================
```

---

### æ­¥é©Ÿ 2ï¼šè¨­è¨ˆæ¸…æ´—é‚è¼¯

**èˆ‡ Claude Code å°è©±**ï¼š
```
åŸºæ–¼å“è³ªå ±å‘Šï¼Œè«‹å¹«æˆ‘è¨­è¨ˆæ¸…æ´—é‚è¼¯ï¼š
1. çµ±ä¸€æ—¥æœŸæ ¼å¼ç‚º YYYY-MM-DD
2. è™•ç† amount ç©ºå€¼ï¼ˆç”¨ä¸­ä½æ•¸å¡«å……ï¼‰
3. æ¸…ç† product_name çš„ç©ºæ ¼
4. ç§»é™¤é‡è¤‡è¨˜éŒ„
5. éæ¿¾æ‰ç„¡æ•ˆæ—¥æœŸçš„è¨˜éŒ„

è«‹ç”Ÿæˆå®Œæ•´çš„æ¸…æ´—å‡½æ•¸
```

**AI ç”Ÿæˆçš„æ¸…æ´—ä»£ç¢¼**ï¼š
```python
def clean_sales_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Clean sales data

    Args:
        df: Raw DataFrame

    Returns:
        Cleaned DataFrame
    """
    print("\nğŸ§¹ Cleaning data...\n")

    df_clean = df.copy()
    initial_rows = len(df_clean)

    # 1. Standardize date format
    print("1ï¸âƒ£ Standardizing date format...")
    def parse_date(date_str):
        """Try multiple date formats"""
        if pd.isna(date_str):
            return pd.NaT

        formats = ['%Y-%m-%d', '%d/%m/%Y', '%m-%d-%Y']
        for fmt in formats:
            try:
                return pd.to_datetime(date_str, format=fmt)
            except:
                continue
        return pd.NaT

    df_clean['date'] = df_clean['date'].apply(parse_date)
    invalid_dates = df_clean['date'].isna().sum()
    print(f"   - Converted dates, {invalid_dates} invalid dates found")

    # 2. Handle missing amounts
    print("\n2ï¸âƒ£ Handling missing amounts...")
    missing_count = df_clean['amount'].isna().sum()
    if missing_count > 0:
        median_amount = df_clean['amount'].median()
        df_clean['amount'].fillna(median_amount, inplace=True)
        print(f"   - Filled {missing_count} missing values with median: ${median_amount:.2f}")
    else:
        print(f"   - No missing amounts")

    # 3. Clean product names
    print("\n3ï¸âƒ£ Cleaning product names...")
    df_clean['product_name'] = df_clean['product_name'].str.strip()
    df_clean['product_name'] = df_clean['product_name'].str.replace(r'\s+', ' ', regex=True)
    print(f"   - Removed extra spaces")

    # 4. Remove duplicates
    print("\n4ï¸âƒ£ Removing duplicates...")
    before_dedup = len(df_clean)
    df_clean.drop_duplicates(inplace=True)
    after_dedup = len(df_clean)
    removed = before_dedup - after_dedup
    print(f"   - Removed {removed} duplicate records")

    # 5. Filter invalid dates
    print("\n5ï¸âƒ£ Filtering invalid records...")
    df_clean = df_clean[df_clean['date'].notna()]
    final_rows = len(df_clean)
    filtered = initial_rows - final_rows
    print(f"   - Filtered {filtered} records with invalid dates")

    print(f"\nâœ… Cleaning completed: {initial_rows} â†’ {final_rows} rows")

    return df_clean

# Apply cleaning
df_cleaned = clean_sales_data(df)

# Display cleaned data
print("\n" + "=" * 50)
print("Cleaned Data Preview")
print("=" * 50)
print(df_cleaned)
```

**è¼¸å‡ºç¯„ä¾‹**ï¼š
```
ğŸ§¹ Cleaning data...

1ï¸âƒ£ Standardizing date format...
   - Converted dates, 1 invalid dates found

2ï¸âƒ£ Handling missing amounts...
   - Filled 1 missing values with median: $1299.99

3ï¸âƒ£ Cleaning product names...
   - Removed extra spaces

4ï¸âƒ£ Removing duplicates...
   - Removed 1 duplicate records

5ï¸âƒ£ Filtering invalid records...
   - Filtered 1 records with invalid dates

âœ… Cleaning completed: 7 â†’ 5 rows

==================================================
Cleaned Data Preview
==================================================
        date  product_name      category   amount region
0 2025-01-30  iPhone 15 Pro  Electronics  1299.99  North
1 2025-01-30  Samsung Galaxy  Electronics  1299.99  South
2 2025-01-30    MacBook Pro   Electronics  2499.99   East
3 2025-01-31       iPad Air   Electronics   799.99   West
4 2025-02-01  iPhone 15 Pro  Electronics  1299.99  South
```

---

### æ­¥é©Ÿ 3ï¼šå®Œæ•´è…³æœ¬ï¼ˆå«éŒ¯èª¤è™•ç†ï¼‰

**`clean_data.py`**ï¼š
```python
#!/usr/bin/env python3
"""
CSV Data Cleaning Script

Automatically clean dirty CSV files.
"""

import pandas as pd
import logging
from pathlib import Path

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def clean_sales_data(df: pd.DataFrame) -> pd.DataFrame:
    """Clean sales data with comprehensive error handling"""
    logger.info("Starting data cleaning process")

    df_clean = df.copy()
    initial_rows = len(df_clean)

    try:
        # Date standardization
        def parse_date(date_str):
            if pd.isna(date_str):
                return pd.NaT
            formats = ['%Y-%m-%d', '%d/%m/%Y', '%m-%d-%Y']
            for fmt in formats:
                try:
                    return pd.to_datetime(date_str, format=fmt)
                except:
                    continue
            return pd.NaT

        df_clean['date'] = df_clean['date'].apply(parse_date)
        logger.info(f"Date standardization completed")

        # Handle missing amounts
        missing_count = df_clean['amount'].isna().sum()
        if missing_count > 0:
            median_amount = df_clean['amount'].median()
            df_clean['amount'].fillna(median_amount, inplace=True)
            logger.info(f"Filled {missing_count} missing amounts")

        # Clean strings
        df_clean['product_name'] = df_clean['product_name'].str.strip()
        df_clean['product_name'] = df_clean['product_name'].str.replace(r'\s+', ' ', regex=True)
        logger.info("String cleaning completed")

        # Remove duplicates
        before = len(df_clean)
        df_clean.drop_duplicates(inplace=True)
        after = len(df_clean)
        logger.info(f"Removed {before - after} duplicates")

        # Filter invalid dates
        df_clean = df_clean[df_clean['date'].notna()]
        final_rows = len(df_clean)
        logger.info(f"Filtering completed: {initial_rows} â†’ {final_rows} rows")

        return df_clean

    except Exception as e:
        logger.error(f"Error during cleaning: {str(e)}")
        raise


def main(input_file: str, output_file: str):
    """Main cleaning pipeline"""
    try:
        # Load data
        logger.info(f"Loading data from {input_file}")
        df = pd.read_csv(input_file)
        logger.info(f"Loaded {len(df)} rows")

        # Clean data
        df_clean = clean_sales_data(df)

        # Save cleaned data
        logger.info(f"Saving cleaned data to {output_file}")
        df_clean.to_csv(output_file, index=False)
        logger.info(f"âœ… Cleaning completed successfully!")

        # Summary
        logger.info(f"\nSummary:")
        logger.info(f"  Input rows:  {len(df)}")
        logger.info(f"  Output rows: {len(df_clean)}")
        logger.info(f"  Removed:     {len(df) - len(df_clean)}")

    except FileNotFoundError:
        logger.error(f"Input file not found: {input_file}")
    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}")
        raise


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Clean CSV data')
    parser.add_argument('--input', required=True, help='Input CSV file')
    parser.add_argument('--output', required=True, help='Output CSV file')

    args = parser.parse_args()

    main(args.input, args.output)
```

**åŸ·è¡Œ**ï¼š
```bash
python clean_data.py --input dirty_sales_data.csv --output cleaned_sales_data.csv
```

**è¼¸å‡º**ï¼š
```
2025-10-30 10:30:00 - INFO - Loading data from dirty_sales_data.csv
2025-10-30 10:30:00 - INFO - Loaded 7 rows
2025-10-30 10:30:00 - INFO - Starting data cleaning process
2025-10-30 10:30:00 - INFO - Date standardization completed
2025-10-30 10:30:00 - INFO - Filled 1 missing amounts
2025-10-30 10:30:00 - INFO - String cleaning completed
2025-10-30 10:30:00 - INFO - Removed 1 duplicates
2025-10-30 10:30:00 - INFO - Filtering completed: 7 â†’ 5 rows
2025-10-30 10:30:00 - INFO - Saving cleaned data to cleaned_sales_data.csv
2025-10-30 10:30:00 - INFO - âœ… Cleaning completed successfully!

2025-10-30 10:30:00 - INFO - Summary:
2025-10-30 10:30:00 - INFO -   Input rows:  7
2025-10-30 10:30:00 - INFO -   Output rows: 5
2025-10-30 10:30:00 - INFO -   Removed:     2
```

---

## âœ… é©—è­‰çµæœ

### æª¢æŸ¥æ¸…æ´—å¾Œè³‡æ–™

**`verify_cleaned_data.py`**ï¼š
```python
import pandas as pd

# Load cleaned data
df = pd.read_csv('cleaned_sales_data.csv')

print("=" * 50)
print("Verification Report")
print("=" * 50)

# Check 1: No missing values
print("\n1. Missing Values Check:")
missing = df.isnull().sum()
if missing.sum() == 0:
    print("   âœ… No missing values")
else:
    print("   âŒ Still has missing values:")
    print(missing[missing > 0])

# Check 2: Date format
print("\n2. Date Format Check:")
try:
    df['date'] = pd.to_datetime(df['date'])
    print(f"   âœ… All dates are valid (from {df['date'].min()} to {df['date'].max()})")
except:
    print("   âŒ Invalid dates found")

# Check 3: No duplicates
print("\n3. Duplicate Check:")
dup_count = df.duplicated().sum()
if dup_count == 0:
    print("   âœ… No duplicates")
else:
    print(f"   âŒ {dup_count} duplicates found")

# Check 4: String quality
print("\n4. String Quality Check:")
has_extra_spaces = df['product_name'].str.contains(r'^\s+|\s+$|\s{2,}', na=False).sum()
if has_extra_spaces == 0:
    print("   âœ… No extra spaces in product names")
else:
    print(f"   âŒ {has_extra_spaces} records still have extra spaces")

# Check 5: Data types
print("\n5. Data Types:")
print(df.dtypes)

print("\n" + "=" * 50)
print("âœ… Verification completed!")
print("=" * 50)
```

---

## ğŸ¯ å­¸ç¿’æª¢æŸ¥é»

å®Œæˆæœ¬æƒ…å¢ƒé¡Œå¾Œï¼Œä½ æ‡‰è©²èƒ½å¤ ï¼š

- [ ] ç”¨ Pandas åˆ†æè³‡æ–™å“è³ªå•é¡Œ
- [ ] è¨­è¨ˆè³‡æ–™æ¸…æ´—é‚è¼¯
- [ ] ç”¨ AI å¿«é€Ÿç”Ÿæˆæ¸…æ´—ä»£ç¢¼
- [ ] åŠ å…¥å®Œå–„çš„éŒ¯èª¤è™•ç†èˆ‡æ—¥èªŒ
- [ ] é©—è­‰æ¸…æ´—çµæœ

---

## ğŸ’¡ å»¶ä¼¸æŒ‘æˆ°

### æŒ‘æˆ° 1ï¼šè‡ªå‹•åŒ–æ’ç¨‹

è¨­å®š Cron jobï¼Œæ¯å¤©è‡ªå‹•åŸ·è¡Œæ¸…æ´—è…³æœ¬ã€‚

### æŒ‘æˆ° 2ï¼šæ¸…æ´—è¦å‰‡é…ç½®åŒ–

å°‡æ¸…æ´—è¦å‰‡å¯«æˆ YAML é…ç½®æª”ï¼Œè®“è…³æœ¬æ›´éˆæ´»ã€‚

### æŒ‘æˆ° 3ï¼šæ¸…æ´—å ±å‘Š

ç”Ÿæˆè©³ç´°çš„æ¸…æ´—å ±å‘Šï¼ˆMarkdown æˆ– HTMLï¼‰ã€‚

---

**æƒ…å¢ƒç‰ˆæœ¬**ï¼šv1.0
**é›£åº¦**ï¼šâ­â­ åŸºç¤è‡³ä¸­ç´š
**é è¨ˆæ™‚é–“**ï¼š30-45 åˆ†é˜
