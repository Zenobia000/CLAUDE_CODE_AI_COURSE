# B03: è‡ªå‹•åŒ–åˆ†æå ±å‘Šç”Ÿæˆ - å¾ 2 å°æ™‚åˆ° 2 åˆ†é˜

## ğŸ“‹ æƒ…å¢ƒæè¿°

**ä½ çš„ç—›é»**ï¼š
```
æ¯é€±äº”ä¸‹åˆçš„æƒ¡å¤¢ï¼š
- ä¸‹è¼‰éŠ·å”®è³‡æ–™ CSV
- æ‰“é–‹ Excel æ‰‹å‹•è¨ˆç®—
- é€å€‹è£½ä½œåœ–è¡¨
- è¤‡è£½è²¼ä¸Šåˆ° PowerPoint
- æ•´ç†æˆå ±å‘Šç™¼é€çµ¦ä¸»ç®¡

è€—æ™‚ï¼š2 å°æ™‚
éŒ¯èª¤ç‡ï¼šç¶“å¸¸ç®—éŒ¯æˆ–å¿˜è¨˜æ›´æ–°æŸå€‹åœ–è¡¨
```

**ä½ æƒ³è¦çš„**ï¼š
```
ä¸€éµç”Ÿæˆå ±å‘Šï¼š
- è‡ªå‹•è¼‰å…¥è³‡æ–™
- è‡ªå‹•æ¢ç´¢æ€§åˆ†æï¼ˆEDAï¼‰
- è‡ªå‹•ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨
- è‡ªå‹•æ’°å¯«æ´å¯Ÿèˆ‡å»ºè­°
- è¼¸å‡ºå°ˆæ¥­ Markdown/PDF å ±å‘Š

ç›®æ¨™ï¼š2 åˆ†é˜å®Œæˆ
```

---

## ğŸ¯ å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬é¡Œå¾Œï¼Œä½ å°‡èƒ½å¤ ï¼š
- [ ] ç”¨ AI è‡ªå‹•ç”Ÿæˆæ¢ç´¢æ€§åˆ†æä»£ç¢¼
- [ ] è‡ªå‹•ç”¢å‡ºå¤šç¨®è³‡æ–™è¦–è¦ºåŒ–åœ–è¡¨
- [ ] ç”¨ AI æå–é—œéµæ´å¯Ÿèˆ‡è¶¨å‹¢
- [ ] ç”Ÿæˆçµæ§‹åŒ–çš„åˆ†æå ±å‘Š
- [ ] è¨­å®šè‡ªå‹•åŒ–æ’ç¨‹ï¼ˆå¯é¸ï¼‰

**æ™‚é–“**ï¼š30-45 åˆ†é˜

---

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

### å ±å‘Šç”Ÿæˆæµç¨‹

```
CSV è³‡æ–™
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. è³‡æ–™è¼‰å…¥èˆ‡æ¸…æ´—    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. æ¢ç´¢æ€§åˆ†æ (EDA) â”‚
â”‚   - åŸºæœ¬çµ±è¨ˆ         â”‚
â”‚   - ç¼ºå¤±å€¼æª¢æŸ¥       â”‚
â”‚   - åˆ†ä½ˆåˆ†æ         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. è¦–è¦ºåŒ–ç”Ÿæˆ        â”‚
â”‚   - è¶¨å‹¢åœ–          â”‚
â”‚   - åˆ†ä½ˆåœ–          â”‚
â”‚   - å°æ¯”åœ–          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. æ´å¯Ÿæå–          â”‚
â”‚   - é—œéµè¶¨å‹¢         â”‚
â”‚   - ç•°å¸¸åµæ¸¬         â”‚
â”‚   - å»ºè­°ç”Ÿæˆ         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Markdown å ±å‘Š
```

---

## ğŸ“ ä»»å‹™éšæ®µ

### éšæ®µ 1ï¼šç’°å¢ƒæº–å‚™ï¼ˆ5 åˆ†é˜ï¼‰

**ä»»å‹™ 1.1**ï¼šå®‰è£ä¾è³´

```bash
# å‰µå»ºå°ˆæ¡ˆç›®éŒ„
mkdir auto-report
cd auto-report

# å®‰è£å¿…è¦å¥—ä»¶
pip install pandas matplotlib seaborn openai python-dotenv
```

**ä»»å‹™ 1.2**ï¼šæº–å‚™æ¸¬è©¦è³‡æ–™

å‰µå»ºç¯„ä¾‹éŠ·å”®è³‡æ–™ `sales_data.csv`ï¼š
```bash
cat > sales_data.csv << 'EOF'
date,product,category,quantity,revenue,region
2024-01-01,Product A,Electronics,15,4500,North
2024-01-01,Product B,Clothing,25,2500,South
2024-01-02,Product A,Electronics,18,5400,North
2024-01-02,Product C,Electronics,12,3600,East
2024-01-03,Product B,Clothing,30,3000,South
2024-01-03,Product A,Electronics,20,6000,North
2024-01-04,Product C,Electronics,15,4500,East
2024-01-04,Product D,Furniture,8,8000,West
2024-01-05,Product A,Electronics,22,6600,North
2024-01-05,Product B,Clothing,28,2800,South
EOF
```

**ä»»å‹™ 1.3**ï¼šè¨­å®š API Key

å‰µå»º `.env`ï¼š
```bash
OPENAI_API_KEY=your_openai_api_key_here
```

---

### éšæ®µ 2ï¼šè³‡æ–™æ¢ç´¢èˆ‡æ¸…æ´—ï¼ˆ10 åˆ†é˜ï¼‰

**ä»»å‹™ 2.1**ï¼šå¿«é€Ÿ EDA

å‰µå»º `analyze.py`ï¼š
```python
import pandas as pd
import numpy as np
from datetime import datetime

# è¼‰å…¥è³‡æ–™
df = pd.read_csv('sales_data.csv')
df['date'] = pd.to_datetime(df['date'])

print("=" * 50)
print("è³‡æ–™åŸºæœ¬è³‡è¨Š")
print("=" * 50)
print(f"è³‡æ–™ç­†æ•¸ï¼š{len(df)}")
print(f"æ—¥æœŸç¯„åœï¼š{df['date'].min()} åˆ° {df['date'].max()}")
print(f"ç”¢å“æ•¸é‡ï¼š{df['product'].nunique()}")
print(f"é¡åˆ¥ï¼š{df['category'].unique().tolist()}")
print(f"åœ°å€ï¼š{df['region'].unique().tolist()}")

print("\n" + "=" * 50)
print("åŸºæœ¬çµ±è¨ˆ")
print("=" * 50)
print(df.describe())

print("\n" + "=" * 50)
print("ç¼ºå¤±å€¼æª¢æŸ¥")
print("=" * 50)
print(df.isnull().sum())

print("\n" + "=" * 50)
print("å„é¡åˆ¥éŠ·å”®ç¸½è¦½")
print("=" * 50)
print(df.groupby('category').agg({
    'quantity': 'sum',
    'revenue': 'sum'
}).sort_values('revenue', ascending=False))
```

**åŸ·è¡Œ**ï¼š
```bash
python analyze.py
```

**ä»»å‹™ 2.2**ï¼šç”¨ AI ç”Ÿæˆæ·±åº¦åˆ†æ

```
User: "åˆ†æé€™ä»½éŠ·å”®è³‡æ–™ï¼Œæä¾›ï¼š
1. è³‡æ–™å“è³ªå ±å‘Šï¼ˆç¼ºå¤±å€¼ã€ç•°å¸¸å€¼ï¼‰
2. éŠ·å”®è¶¨å‹¢åˆ†æ
3. ç”¢å“èˆ‡é¡åˆ¥è¡¨ç¾
4. åœ°å€å·®ç•°åˆ†æ
5. æ½›åœ¨å•é¡Œèˆ‡å»ºè­°

è«‹ç”Ÿæˆ Python ä»£ç¢¼ä¾†å®Œæˆé€™äº›åˆ†æã€‚"
```

---

### éšæ®µ 3ï¼šè‡ªå‹•åŒ–è¦–è¦ºåŒ–ï¼ˆ10 åˆ†é˜ï¼‰

**ä»»å‹™ 3.1**ï¼šç”Ÿæˆå¤šç¨®åœ–è¡¨

å‰µå»º `visualize.py`ï¼š
```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os

# è¨­å®šä¸­æ–‡å­—é«”ï¼ˆå¦‚æœéœ€è¦ï¼‰
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # Mac
# plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']  # Windows

# å‰µå»ºè¼¸å‡ºç›®éŒ„
os.makedirs('charts', exist_ok=True)

# è¼‰å…¥è³‡æ–™
df = pd.read_csv('sales_data.csv')
df['date'] = pd.to_datetime(df['date'])

# åœ–è¡¨ 1ï¼šæ¯æ—¥ç‡Ÿæ”¶è¶¨å‹¢
plt.figure(figsize=(10, 6))
daily_revenue = df.groupby('date')['revenue'].sum()
plt.plot(daily_revenue.index, daily_revenue.values, marker='o')
plt.title('Daily Revenue Trend', fontsize=16, fontweight='bold')
plt.xlabel('Date')
plt.ylabel('Revenue ($)')
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('charts/daily_revenue.png', dpi=300)
plt.close()

# åœ–è¡¨ 2ï¼šç”¢å“é¡åˆ¥ç‡Ÿæ”¶ä½”æ¯”
plt.figure(figsize=(8, 8))
category_revenue = df.groupby('category')['revenue'].sum()
plt.pie(category_revenue.values, labels=category_revenue.index,
        autopct='%1.1f%%', startangle=90)
plt.title('Revenue by Category', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('charts/category_pie.png', dpi=300)
plt.close()

# åœ–è¡¨ 3ï¼šåœ°å€éŠ·å”®å°æ¯”
plt.figure(figsize=(10, 6))
region_data = df.groupby('region').agg({
    'quantity': 'sum',
    'revenue': 'sum'
})
x = np.arange(len(region_data))
width = 0.35
fig, ax = plt.subplots(figsize=(10, 6))
ax.bar(x - width/2, region_data['quantity'], width, label='Quantity', alpha=0.8)
ax.bar(x + width/2, region_data['revenue']/100, width, label='Revenue (x100)', alpha=0.8)
ax.set_xlabel('Region')
ax.set_ylabel('Value')
ax.set_title('Sales by Region', fontsize=16, fontweight='bold')
ax.set_xticks(x)
ax.set_xticks(region_data.index)
ax.legend()
plt.tight_layout()
plt.savefig('charts/region_comparison.png', dpi=300)
plt.close()

# åœ–è¡¨ 4ï¼šç”¢å“è¡¨ç¾ç†±åœ–
plt.figure(figsize=(10, 8))
product_region = df.pivot_table(
    values='revenue',
    index='product',
    columns='region',
    aggfunc='sum',
    fill_value=0
)
sns.heatmap(product_region, annot=True, fmt='.0f', cmap='YlOrRd')
plt.title('Product Performance by Region', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('charts/product_heatmap.png', dpi=300)
plt.close()

print("âœ… æ‰€æœ‰åœ–è¡¨å·²ç”Ÿæˆåˆ° charts/ ç›®éŒ„")
```

**ä»»å‹™ 3.2**ï¼šåŸ·è¡Œä¸¦æª¢è¦–åœ–è¡¨

```bash
python visualize.py
ls charts/
```

---

### éšæ®µ 4ï¼šAI æ´å¯Ÿæå–ï¼ˆ10 åˆ†é˜ï¼‰

**ä»»å‹™ 4.1**ï¼šç”¨ AI åˆ†æåœ–è¡¨ä¸¦æå–æ´å¯Ÿ

å‰µå»º `generate_insights.py`ï¼š
```python
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# è¼‰å…¥è³‡æ–™ä¸¦è¨ˆç®—é—œéµæŒ‡æ¨™
df = pd.read_csv('sales_data.csv')
df['date'] = pd.to_datetime(df['date'])

# å½™æ•´é—œéµæ•¸æ“š
summary = {
    "total_revenue": df['revenue'].sum(),
    "total_quantity": df['quantity'].sum(),
    "avg_daily_revenue": df.groupby('date')['revenue'].sum().mean(),
    "top_category": df.groupby('category')['revenue'].sum().idxmax(),
    "top_region": df.groupby('region')['revenue'].sum().idxmax(),
    "best_product": df.groupby('product')['revenue'].sum().idxmax(),
    "revenue_by_category": df.groupby('category')['revenue'].sum().to_dict(),
    "revenue_by_region": df.groupby('region')['revenue'].sum().to_dict(),
}

# æ§‹å»ºæç¤ºè©
prompt = f"""
Based on the following sales data summary, provide a comprehensive analysis:

Data Summary:
- Total Revenue: ${summary['total_revenue']:,.2f}
- Total Units Sold: {summary['total_quantity']}
- Average Daily Revenue: ${summary['avg_daily_revenue']:,.2f}
- Top Category: {summary['top_category']}
- Top Region: {summary['top_region']}
- Best Selling Product: {summary['best_product']}

Revenue by Category:
{summary['revenue_by_category']}

Revenue by Region:
{summary['revenue_by_region']}

Please provide:
1. Key Trends (3-4 points)
2. Notable Insights (3-4 points)
3. Potential Issues or Concerns (2-3 points)
4. Actionable Recommendations (3-4 points)

Format the response in clear Markdown format with headers and bullet points.
"""

# èª¿ç”¨ AI ç”Ÿæˆæ´å¯Ÿ
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a data analyst providing business insights."},
        {"role": "user", "content": prompt}
    ],
    temperature=0.7
)

insights = response.choices[0].message.content

print("=" * 50)
print("AI ç”Ÿæˆçš„æ´å¯Ÿ")
print("=" * 50)
print(insights)

# å„²å­˜æ´å¯Ÿåˆ°æª”æ¡ˆ
with open('insights.md', 'w') as f:
    f.write(insights)

print("\nâœ… æ´å¯Ÿå·²å„²å­˜åˆ° insights.md")
```

**ä»»å‹™ 4.2**ï¼šåŸ·è¡Œä¸¦æŸ¥çœ‹æ´å¯Ÿ

```bash
python generate_insights.py
cat insights.md
```

---

### éšæ®µ 5ï¼šç”Ÿæˆå®Œæ•´å ±å‘Šï¼ˆ10 åˆ†é˜ï¼‰

**ä»»å‹™ 5.1**ï¼šæ•´åˆæ‰€æœ‰å…ƒç´ 

å‰µå»º `generate_report.py`ï¼š
```python
import pandas as pd
from datetime import datetime
import os

def generate_report():
    # è¼‰å…¥è³‡æ–™
    df = pd.read_csv('sales_data.csv')
    df['date'] = pd.to_datetime(df['date'])

    # è¼‰å…¥ AI æ´å¯Ÿ
    with open('insights.md', 'r') as f:
        insights = f.read()

    # ç”Ÿæˆå ±å‘Š
    report = f"""# éŠ·å”®åˆ†æå ±å‘Š

**ç”Ÿæˆæ™‚é–“**ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

**åˆ†ææœŸé–“**ï¼š{df['date'].min().strftime('%Y-%m-%d')} è‡³ {df['date'].max().strftime('%Y-%m-%d')}

---

## åŸ·è¡Œæ‘˜è¦

æœ¬å ±å‘Šåˆ†æäº† {len(df)} ç­†éŠ·å”®äº¤æ˜“è³‡æ–™ï¼Œæ¶µè“‹ {df['date'].nunique()} å¤©çš„éŠ·å”®è¨˜éŒ„ã€‚

**é—œéµæŒ‡æ¨™**ï¼š
- **ç¸½ç‡Ÿæ”¶**ï¼š${df['revenue'].sum():,.2f}
- **ç¸½éŠ·å”®æ•¸é‡**ï¼š{df['quantity'].sum()} ä»¶
- **å¹³å‡æ¯æ—¥ç‡Ÿæ”¶**ï¼š${df.groupby('date')['revenue'].sum().mean():,.2f}
- **äº¤æ˜“æ•¸é‡**ï¼š{len(df)} ç­†

---

## è³‡æ–™æ¦‚è¦½

### åŸºæœ¬çµ±è¨ˆ

| æŒ‡æ¨™ | æ•¸å€¼ |
|------|------|
| ç¸½ç‡Ÿæ”¶ | ${df['revenue'].sum():,.2f} |
| ç¸½éŠ·å”®é‡ | {df['quantity'].sum()} |
| å¹³å‡å–®åƒ¹ | ${df['revenue'].mean():,.2f} |
| ç”¢å“ç¨®é¡ | {df['product'].nunique()} |
| éŠ·å”®åœ°å€ | {df['region'].nunique()} |

### é¡åˆ¥è¡¨ç¾

"""

    # é¡åˆ¥è¡¨ç¾è¡¨æ ¼
    category_stats = df.groupby('category').agg({
        'quantity': 'sum',
        'revenue': 'sum'
    }).sort_values('revenue', ascending=False)

    report += "\n| é¡åˆ¥ | éŠ·å”®é‡ | ç‡Ÿæ”¶ | ä½”æ¯” |\n"
    report += "|------|--------|------|------|\n"
    for cat, row in category_stats.iterrows():
        pct = (row['revenue'] / df['revenue'].sum()) * 100
        report += f"| {cat} | {row['quantity']} | ${row['revenue']:,.2f} | {pct:.1f}% |\n"

    report += "\n### åœ°å€è¡¨ç¾\n\n"

    # åœ°å€è¡¨ç¾è¡¨æ ¼
    region_stats = df.groupby('region').agg({
        'quantity': 'sum',
        'revenue': 'sum'
    }).sort_values('revenue', ascending=False)

    report += "\n| åœ°å€ | éŠ·å”®é‡ | ç‡Ÿæ”¶ | ä½”æ¯” |\n"
    report += "|------|--------|------|------|\n"
    for reg, row in region_stats.iterrows():
        pct = (row['revenue'] / df['revenue'].sum()) * 100
        report += f"| {reg} | {row['quantity']} | ${row['revenue']:,.2f} | {pct:.1f}% |\n"

    report += "\n---\n\n## è¦–è¦ºåŒ–åˆ†æ\n\n"

    # åŠ å…¥åœ–è¡¨
    charts = [
        ('daily_revenue.png', 'æ¯æ—¥ç‡Ÿæ”¶è¶¨å‹¢'),
        ('category_pie.png', 'é¡åˆ¥ç‡Ÿæ”¶ä½”æ¯”'),
        ('region_comparison.png', 'åœ°å€éŠ·å”®å°æ¯”'),
        ('product_heatmap.png', 'ç”¢å“åœ°å€è¡¨ç¾ç†±åœ–')
    ]

    for chart, title in charts:
        if os.path.exists(f'charts/{chart}'):
            report += f"### {title}\n\n"
            report += f"![{title}](charts/{chart})\n\n"

    report += "---\n\n## AI æ´å¯Ÿèˆ‡å»ºè­°\n\n"
    report += insights

    report += "\n\n---\n\n## é™„éŒ„\n\n"
    report += "### è³‡æ–™ä¾†æº\n"
    report += f"- æª”æ¡ˆï¼šsales_data.csv\n"
    report += f"- è¨˜éŒ„æ•¸ï¼š{len(df)}\n"
    report += f"- åˆ†ææ—¥æœŸï¼š{datetime.now().strftime('%Y-%m-%d')}\n"

    # å„²å­˜å ±å‘Š
    with open('sales_report.md', 'w') as f:
        f.write(report)

    print("=" * 50)
    print("å ±å‘Šç”ŸæˆæˆåŠŸï¼")
    print("=" * 50)
    print(f"å ±å‘Šä½ç½®ï¼šsales_report.md")
    print(f"åœ–è¡¨ç›®éŒ„ï¼šcharts/")
    print(f"AI æ´å¯Ÿï¼šinsights.md")

if __name__ == "__main__":
    generate_report()
```

**ä»»å‹™ 5.2**ï¼šç”Ÿæˆå®Œæ•´å ±å‘Š

```bash
python generate_report.py
```

**ä»»å‹™ 5.3**ï¼šæŸ¥çœ‹å ±å‘Š

```bash
# åœ¨ Markdown ç·¨è¼¯å™¨ä¸­æ‰“é–‹
code sales_report.md

# æˆ–è½‰æ›ç‚º PDFï¼ˆå¯é¸ï¼‰
pip install markdown-pdf
markdown-pdf sales_report.md
```

---

## âœ… æª¢æŸ¥é»

### æª¢æŸ¥é» 1ï¼šåŸºç¤åŠŸèƒ½å®Œæˆ

- [ ] æˆåŠŸè¼‰å…¥ä¸¦åˆ†æè³‡æ–™
- [ ] ç”Ÿæˆè‡³å°‘ 3 ç¨®è¦–è¦ºåŒ–åœ–è¡¨
- [ ] AI æˆåŠŸæå–é—œéµæ´å¯Ÿ
- [ ] ç”Ÿæˆçµæ§‹åŒ– Markdown å ±å‘Š

### æª¢æŸ¥é» 2ï¼šå ±å‘Šå“è³ª

- [ ] å ±å‘ŠåŒ…å«åŸºæœ¬çµ±è¨ˆè³‡è¨Š
- [ ] åœ–è¡¨æ¸…æ™°ä¸”æœ‰æ„ç¾©
- [ ] AI æ´å¯Ÿåˆç†ä¸”å¯åŸ·è¡Œ
- [ ] å ±å‘Šæ ¼å¼å°ˆæ¥­ç¾è§€

### æª¢æŸ¥é» 3ï¼šè‡ªå‹•åŒ–ç¨‹åº¦

- [ ] ä¸€éµåŸ·è¡Œå³å¯ç”Ÿæˆå®Œæ•´å ±å‘Š
- [ ] ç„¡éœ€æ‰‹å‹•èª¿æ•´æˆ–ç·¨è¼¯
- [ ] å¯è™•ç†ä¸åŒçš„è¼¸å…¥è³‡æ–™
- [ ] éŒ¯èª¤è™•ç†å®Œå–„

---

## ğŸ’¡ å„ªåŒ–å»ºè­°

### å„ªåŒ– 1ï¼šæ•´åˆç‚ºå–®ä¸€è…³æœ¬

å‰µå»º `auto_report.py`ï¼š
```python
import subprocess
import sys

def run_command(cmd, description):
    print(f"\n{'='*50}")
    print(f"{description}")
    print(f"{'='*50}")
    result = subprocess.run(cmd, shell=True)
    if result.returncode != 0:
        print(f"âŒ åŸ·è¡Œå¤±æ•—ï¼š{description}")
        sys.exit(1)
    print(f"âœ… å®Œæˆï¼š{description}")

if __name__ == "__main__":
    print("ğŸš€ é–‹å§‹ç”Ÿæˆè‡ªå‹•åŒ–å ±å‘Š...")

    run_command("python analyze.py", "æ­¥é©Ÿ 1/4: è³‡æ–™æ¢ç´¢")
    run_command("python visualize.py", "æ­¥é©Ÿ 2/4: ç”Ÿæˆåœ–è¡¨")
    run_command("python generate_insights.py", "æ­¥é©Ÿ 3/4: AI æ´å¯Ÿæå–")
    run_command("python generate_report.py", "æ­¥é©Ÿ 4/4: ç”Ÿæˆå®Œæ•´å ±å‘Š")

    print("\n" + "="*50)
    print("ğŸ‰ å ±å‘Šç”Ÿæˆå®Œæˆï¼")
    print("="*50)
    print("è«‹æŸ¥çœ‹ï¼šsales_report.md")
```

**ä½¿ç”¨**ï¼š
```bash
python auto_report.py
```

---

### å„ªåŒ– 2ï¼šæ”¯æ´å¤šç¨®è³‡æ–™æ ¼å¼

```python
def load_data(file_path):
    """è‡ªå‹•è­˜åˆ¥ä¸¦è¼‰å…¥è³‡æ–™"""
    if file_path.endswith('.csv'):
        return pd.read_csv(file_path)
    elif file_path.endswith('.xlsx'):
        return pd.read_excel(file_path)
    elif file_path.endswith('.json'):
        return pd.read_json(file_path)
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„æ ¼å¼ï¼š{file_path}")

# ä½¿ç”¨
df = load_data('sales_data.csv')  # æˆ– .xlsx, .json
```

---

### å„ªåŒ– 3ï¼šå¢åŠ ç•°å¸¸åµæ¸¬

```python
def detect_anomalies(df):
    """åµæ¸¬ç•°å¸¸å€¼"""
    # ä½¿ç”¨ IQR æ–¹æ³•
    Q1 = df['revenue'].quantile(0.25)
    Q3 = df['revenue'].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    anomalies = df[(df['revenue'] < lower_bound) | (df['revenue'] > upper_bound)]

    if len(anomalies) > 0:
        print(f"âš ï¸  åµæ¸¬åˆ° {len(anomalies)} ç­†ç•°å¸¸äº¤æ˜“ï¼š")
        print(anomalies[['date', 'product', 'revenue']])
    return anomalies
```

---

### å„ªåŒ– 4ï¼šè¨­å®šè‡ªå‹•åŒ–æ’ç¨‹

**æ–¹æ³• Aï¼šä½¿ç”¨ Cron (Linux/Mac)**

```bash
# ç·¨è¼¯ crontab
crontab -e

# æ¯é€±äº”ä¸‹åˆ 3 é»åŸ·è¡Œ
0 15 * * 5 cd /path/to/auto-report && python auto_report.py
```

**æ–¹æ³• Bï¼šä½¿ç”¨ Windows å·¥ä½œæ’ç¨‹å™¨**

```powershell
# å‰µå»ºæ’ç¨‹ä»»å‹™
schtasks /create /tn "WeeklySalesReport" /tr "python C:\path\to\auto_report.py" /sc weekly /d FRI /st 15:00
```

**æ–¹æ³• Cï¼šä½¿ç”¨ Python schedule å¥—ä»¶**

```python
import schedule
import time

def job():
    print("é–‹å§‹ç”Ÿæˆé€±å ±...")
    subprocess.run("python auto_report.py", shell=True)

# æ¯é€±äº” 15:00 åŸ·è¡Œ
schedule.every().friday.at("15:00").do(job)

while True:
    schedule.run_pending()
    time.sleep(60)
```

---

## ğŸ¯ æ“´å±•æŒ‘æˆ°

### æŒ‘æˆ° 1ï¼šå¤šæœŸå°æ¯”

æ¯”è¼ƒæœ¬é€±èˆ‡ä¸Šé€±çš„æ•¸æ“šï¼š
```python
this_week = df[df['date'] >= '2024-01-01']
last_week = df[df['date'] < '2024-01-01']

comparison = pd.DataFrame({
    'This Week': [
        this_week['revenue'].sum(),
        this_week['quantity'].sum()
    ],
    'Last Week': [
        last_week['revenue'].sum(),
        last_week['quantity'].sum()
    ],
    'Change %': [
        ((this_week['revenue'].sum() - last_week['revenue'].sum())
         / last_week['revenue'].sum() * 100),
        ((this_week['quantity'].sum() - last_week['quantity'].sum())
         / last_week['quantity'].sum() * 100)
    ]
}, index=['Revenue', 'Quantity'])
```

### æŒ‘æˆ° 2ï¼šé æ¸¬ä¸‹é€±éŠ·å”®

ä½¿ç”¨ç°¡å–®ç·šæ€§è¿´æ­¸ï¼š
```python
from sklearn.linear_model import LinearRegression

# æº–å‚™è³‡æ–™
daily_sales = df.groupby('date')['revenue'].sum().reset_index()
daily_sales['day_num'] = range(len(daily_sales))

X = daily_sales[['day_num']]
y = daily_sales['revenue']

# è¨“ç·´æ¨¡å‹
model = LinearRegression()
model.fit(X, y)

# é æ¸¬ä¸‹é€±ï¼ˆå‡è¨­ 7 å¤©å¾Œï¼‰
next_days = [[len(daily_sales) + i] for i in range(1, 8)]
predictions = model.predict(next_days)

print("ä¸‹é€±é æ¸¬ç‡Ÿæ”¶ï¼š")
for i, pred in enumerate(predictions, 1):
    print(f"  Day {i}: ${pred:,.2f}")
```

### æŒ‘æˆ° 3ï¼šéƒµä»¶è‡ªå‹•ç™¼é€

ä½¿ç”¨ `smtplib` ç™¼é€å ±å‘Šï¼š
```python
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.image import MIMEImage

def send_report(to_email):
    msg = MIMEMultipart()
    msg['From'] = 'your_email@example.com'
    msg['To'] = to_email
    msg['Subject'] = f'é€±å ± - {datetime.now().strftime("%Y-%m-%d")}'

    # è®€å–å ±å‘Šå…§å®¹
    with open('sales_report.md', 'r') as f:
        body = f.read()

    msg.attach(MIMEText(body, 'plain'))

    # é™„åŠ åœ–è¡¨ï¼ˆå¯é¸ï¼‰
    for chart in os.listdir('charts'):
        with open(f'charts/{chart}', 'rb') as f:
            img = MIMEImage(f.read())
            img.add_header('Content-ID', f'<{chart}>')
            msg.attach(img)

    # ç™¼é€
    server = smtplib.SMTP('smtp.gmail.com', 587)
    server.starttls()
    server.login('your_email@example.com', 'your_password')
    server.send_message(msg)
    server.quit()
```

### æŒ‘æˆ° 4ï¼šäº’å‹•å¼å„€è¡¨æ¿

ä½¿ç”¨ Streamlitï¼š
```python
import streamlit as st

st.title("éŠ·å”®åˆ†æå„€è¡¨æ¿")

# ä¸Šå‚³æª”æ¡ˆ
uploaded_file = st.file_uploader("ä¸Šå‚³ CSV", type=['csv'])

if uploaded_file:
    df = pd.read_csv(uploaded_file)

    # é¡¯ç¤ºåŸºæœ¬çµ±è¨ˆ
    st.metric("ç¸½ç‡Ÿæ”¶", f"${df['revenue'].sum():,.2f}")
    st.metric("ç¸½éŠ·å”®é‡", df['quantity'].sum())

    # äº’å‹•å¼åœ–è¡¨
    chart_type = st.selectbox("é¸æ“‡åœ–è¡¨",
                              ["æ¯æ—¥è¶¨å‹¢", "é¡åˆ¥åˆ†ä½ˆ", "åœ°å€å°æ¯”"])

    if chart_type == "æ¯æ—¥è¶¨å‹¢":
        st.line_chart(df.groupby('date')['revenue'].sum())
```

---

## ğŸ“š ç¸½çµ

å®Œæˆæœ¬é¡Œå¾Œï¼Œä½ æ‡‰è©²ï¼š

**æŒæ¡çš„æŠ€èƒ½**ï¼š
- âœ… è‡ªå‹•åŒ–è³‡æ–™æ¢ç´¢èˆ‡åˆ†æ
- âœ… æ‰¹æ¬¡ç”Ÿæˆå¤šç¨®è¦–è¦ºåŒ–åœ–è¡¨
- âœ… ç”¨ AI æå–æ¥­å‹™æ´å¯Ÿ
- âœ… ç”Ÿæˆçµæ§‹åŒ–åˆ†æå ±å‘Š

**ç†è§£çš„æ¦‚å¿µ**ï¼š
- âœ… EDAï¼ˆæ¢ç´¢æ€§è³‡æ–™åˆ†æï¼‰çš„æµç¨‹
- âœ… è³‡æ–™è¦–è¦ºåŒ–çš„æœ€ä½³å¯¦è¸
- âœ… AI åœ¨è³‡æ–™åˆ†æä¸­çš„æ‡‰ç”¨å ´æ™¯
- âœ… å ±å‘Šè‡ªå‹•åŒ–çš„åƒ¹å€¼

**å»ºç«‹çš„èªçŸ¥**ï¼š
- âœ… è‡ªå‹•åŒ–å¯ä»¥ç¯€çœ 90% ä»¥ä¸Šçš„æ™‚é–“
- âœ… AI é©åˆè™•ç†é‡è¤‡æ€§åˆ†æä»»å‹™
- âœ… æ¨™æº–åŒ–æµç¨‹æ˜¯è‡ªå‹•åŒ–çš„å‰æ
- âœ… å ±å‘Šæ ¼å¼åŒ–æ¯”å…§å®¹ç”Ÿæˆæ›´ç°¡å–®

---

**ä¸‹ä¸€æ­¥**ï¼š
- æŒ‘æˆ°çµ„åˆç´š C03ï¼šéŠ·å”®æ•¸æ“šå„€è¡¨æ¿ï¼ˆæ›´å®Œæ•´çš„å¯¦ä½œï¼‰
- æˆ–å˜—è©¦å°‡æœ¬ç³»çµ±æ‡‰ç”¨åˆ°ä½ çš„çœŸå¯¦å·¥ä½œå ´æ™¯

**è¨˜ä½**ï¼š
> è‡ªå‹•åŒ–çš„é—œéµæ˜¯æ¨™æº–åŒ–æµç¨‹ã€‚
> AI æ“…é•·è™•ç†é‡è¤‡æ€§ä»»å‹™ã€‚
> å¾ç°¡å–®å ±å‘Šé–‹å§‹ï¼Œé€æ­¥æ“´å±•åŠŸèƒ½ã€‚
> 2 å°æ™‚ â†’ 2 åˆ†é˜ï¼Œé€™ä¸æ˜¯å¤¢æƒ³ã€‚
