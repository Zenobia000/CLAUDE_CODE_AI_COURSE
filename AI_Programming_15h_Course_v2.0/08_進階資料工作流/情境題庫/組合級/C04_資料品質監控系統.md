# C04 - 資料品質監控系統

## 📌 情境描述

### 業務背景
你的公司運營著一個電商平台,數據從多個來源流入數據倉庫:
- 訂單系統(每日 10,000+ 筆)
- 用戶行為追蹤(每日 100,000+ 事件)
- 供應商數據同步(每週)

BI 團隊依賴這些數據做決策,但經常遇到數據品質問題:
- 某天報表顯示銷售額為 $0(實際是資料管線失敗)
- 新產品訂單找不到產品資訊(產品表同步延遲)
- 用戶年齡出現負數(數據清洗問題)

這些問題通常在下游報表異常時才被發現,導致錯誤決策。

### 現況痛點
- **被動發現**:數據問題在使用時才發現,不是在產生時
- **影響範圍不明**:不知道哪些報表受影響
- **缺乏追蹤**:不知道數據品質趨勢(是變好還是變差?)
- **手動檢查**:依賴分析師人工抽查
- **修復緩慢**:發現問題後找不到根因

### 任務目標
使用 Claude Code 協助開發資料品質監控系統,實現:
- 自動化品質檢查(Schema、完整性、準確性、一致性)
- 異常實時告警(Slack/Email)
- 品質趨勢追蹤(儀表板可視化)
- 數據血緣追蹤(快速定位問題來源)
- 自動化修復建議(AI 根因分析)

---

## 🎯 學習目標

完成本情境後,你將能夠:

- [ ] **設計品質監控框架**:理解數據品質的多個維度
- [ ] **實作自動化檢查**:Schema 驗證、完整性、異常值檢測
- [ ] **建立告警機制**:閾值設定、告警路由、降噪策略
- [ ] **品質指標體系**:定義 KPIs、追蹤趨勢
- [ ] **數據血緣追蹤**:記錄數據流向,快速定位問題
- [ ] **AI 根因分析**:LLM 輔助診斷異常原因
- [ ] **Great Expectations 實作**:使用業界標準工具

**時間估計**:2.5-3 小時

---

## 🏗️ 系統架構

```
┌─────────────────────────────────────────────────┐
│         Data Sources (監控目標)                  │
├────────────┬────────────┬────────────┬──────────┤
│  Orders    │  Users     │  Products  │  Events  │
│  Table     │  Table     │  Table     │  Stream  │
└──────┬─────┴──────┬─────┴──────┬─────┴────┬─────┘
       │            │            │          │
       └────────────┴────────────┴──────────┘
                    ▼
        ┌─────────────────────────┐
        │   Quality Checks Layer  │
        │  - Schema validation    │
        │  - Completeness check   │
        │  - Accuracy check       │
        │  - Consistency check    │
        │  - Timeliness check     │
        └────────────┬────────────┘
                     ▼
        ┌─────────────────────────┐
        │  Great Expectations     │
        │  - Expectation suites   │
        │  - Validation results   │
        │  - Data docs            │
        └────────────┬────────────┘
                     ▼
        ┌─────────────────────────┐
        │    Results Storage      │
        │  - DuckDB / PostgreSQL  │
        │  - Validation history   │
        │  - Anomaly records      │
        └────────────┬────────────┘
                     │
             ┌───────┴───────┐
             ▼               ▼
    ┌────────────────┐  ┌────────────────┐
    │ Alert Engine   │  │ Dashboard UI   │
    │ - Threshold    │  │ - Metrics view │
    │ - Slack/Email  │  │ - Trend charts │
    │ - Deduplication│  │ - Drill-down   │
    └────────┬───────┘  └────────────────┘
             ▼
    ┌─────────────────────────┐
    │   AI Root Cause Layer   │
    │  - LLM analysis         │
    │  - Pattern detection    │
    │  - Fix suggestions      │
    └─────────────────────────┘
             │
             ▼
    ┌─────────────────────────┐
    │   Data Lineage Graph    │
    │  - Source tracking      │
    │  - Impact analysis      │
    │  - Dependency map       │
    └─────────────────────────┘
```

---

## 📋 核心任務

### 階段一:品質檢查框架建立(40 分鐘)

**任務**:
1. 定義數據品質維度(Schema、完整性、準確性、一致性、時效性)
2. 使用 Great Expectations 建立 Expectation Suites
3. 實作 Schema 驗證(欄位類型、必填欄位)
4. 實作完整性檢查(NULL 比例、唯一性)

**與 AI 協作要點**:
- "解釋數據品質的六大維度:完整性、準確性、一致性、時效性、唯一性、有效性"
- "使用 Great Expectations 建立 orders 表的 Expectation Suite"
- "定義期望:order_id 必須唯一、amount > 0、status 只能是特定值"
- "實作 expect_column_values_to_not_be_null(column='customer_id')"

**檢查點**:
- [ ] Great Expectations 專案初始化完成
- [ ] 每個核心表有對應的 Expectation Suite
- [ ] Schema 驗證:欄位類型、必填欄位
- [ ] 完整性檢查:NULL 比例、唯一性約束

---

### 階段二:異常檢測與閾值設定(40 分鐘)

**任務**:
1. 數值範圍檢查(銷售額、年齡、數量的合理範圍)
2. 統計異常檢測(Z-score、IQR)
3. 業務規則驗證(訂單金額 = 單價 × 數量)
4. 時效性檢查(數據更新延遲)

**與 AI 協作要點**:
- "設定合理範圍:訂單金額 $1-$10,000、用戶年齡 13-120"
- "使用 Z-score 檢測異常值,閾值設為 3"
- "驗證業務規則:expect_column_pair_values_A_to_be_greater_than_B"
- "檢查時效性:expect_table_row_count_to_be_between 設定每日最小行數"

**檢查點**:
- [ ] 數值範圍檢查:識別超出合理範圍的值
- [ ] 統計異常:Z-score > 3 標記為異常
- [ ] 業務規則驗證通過
- [ ] 時效性檢查:資料更新延遲 > 2 小時告警

---

### 階段三:告警機制與降噪(35 分鐘)

**任務**:
1. 告警規則定義(哪些檢查失敗需要告警)
2. 告警優先級分級(Critical / Warning / Info)
3. 告警路由(Critical → Slack,Warning → Email)
4. 告警降噪(避免重複告警、靜默期)

**與 AI 協作要點**:
- "設計告警規則:NULL 比例 > 10% → Critical,5-10% → Warning"
- "實作 Slack Webhook 發送告警,包含:表名、檢查項、失敗原因、影響行數"
- "實作告警去重:同一問題 1 小時內只告警一次"
- "靜默期:已知問題可以手動設定靜默 24 小時"

**檢查點**:
- [ ] 告警規則定義清晰(每個檢查的閾值和優先級)
- [ ] Slack 告警格式良好(易讀、可操作)
- [ ] 告警去重生效(不會重複轟炸)
- [ ] 可以手動設定靜默期

---

### 階段四:品質儀表板與趨勢追蹤(35 分鐘)

**任務**:
1. 設計品質指標 KPIs(通過率、異常率、平均品質分數)
2. 時間序列圖表(品質趨勢)
3. 熱力圖(各表品質矩陣)
4. 詳細 Drill-down(點擊表名查看具體失敗檢查)

**與 AI 協作要點**:
- "設計品質分數計算:Quality Score = (通過檢查數 / 總檢查數) × 100"
- "用 Plotly 繪製過去 30 天品質趨勢折線圖"
- "實作熱力圖:行=表名,列=檢查類型,顏色=通過率"
- "Drill-down:點擊某個表,顯示該表所有檢查的詳細結果"

**檢查點**:
- [ ] 儀表板顯示整體品質分數
- [ ] 趨勢圖顯示品質變化(改善/惡化)
- [ ] 熱力圖清楚顯示問題集中區域
- [ ] 可以 Drill-down 查看詳細失敗記錄

---

### 階段五:AI 根因分析與數據血緣(30 分鐘)

**任務**:
1. 數據血緣追蹤(記錄數據來源和轉換)
2. AI 根因分析(LLM 解釋異常可能原因)
3. 修復建議生成(基於歷史問題和解決方案)
4. 影響範圍分析(哪些下游表受影響)

**與 AI 協作要點**:
- "設計數據血緣 Schema:source_table → transformation → target_table"
- "當檢測到異常時,提供上下文給 LLM:表名、檢查項、失敗詳情、近期變更"
- "Prompt:分析可能原因(上游數據問題、轉換邏輯錯誤、Schema 變更)"
- "根據血緣圖,識別受影響的下游表和報表"

**範例 Prompt**:
```
Data Quality Issue Detected:

Table: orders
Check: expect_column_values_to_be_between(amount, min=1, max=10000)
Failure: 127 rows have amount < 0
Timeline: Started appearing on 2024-01-15 08:00
Recent Changes: orders table schema updated on 2024-01-14

Please analyze:
1. Most likely root cause
2. Upstream or downstream issue?
3. Recommended fix
4. How to prevent in future
```

**檢查點**:
- [ ] 數據血緣圖記錄完整(來源、轉換、目標)
- [ ] AI 分析給出 3 個可能原因
- [ ] 修復建議可操作(具體步驟)
- [ ] 影響範圍分析:列出受影響的下游對象

---

## 💡 學習重點

### 1. 數據品質的六大維度

**維度定義**:

| 維度 | 定義 | 檢查方法 | 範例 |
|------|------|----------|------|
| **完整性(Completeness)** | 數據是否完整,無缺失 | NULL 比例、行數檢查 | `customer_id` 不應為 NULL |
| **準確性(Accuracy)** | 數據是否正確,符合事實 | 業務規則驗證 | 訂單金額 = 單價 × 數量 |
| **一致性(Consistency)** | 不同來源數據是否一致 | 跨表比對 | 訂單表的 `user_id` 必須存在於用戶表 |
| **時效性(Timeliness)** | 數據是否及時更新 | 更新時間檢查 | 訂單表每小時至少新增 100 筆 |
| **唯一性(Uniqueness)** | 主鍵是否唯一 | 去重檢查 | `order_id` 不能重複 |
| **有效性(Validity)** | 數據是否在合理範圍 | 範圍檢查、格式檢查 | 年齡 13-120,Email 格式正確 |

**AI 協作策略**:
- "對於電商訂單表,列出每個維度應該檢查的項目"
- "設計檢查優先級:哪些是 Critical,哪些是 Warning?"

---

### 2. Great Expectations 最佳實踐

**核心概念**:
- **Expectation**:單一數據品質斷言
- **Expectation Suite**:一組相關 Expectations
- **Checkpoint**:執行驗證的觸發點
- **Data Docs**:自動生成的品質文檔

**常用 Expectations**:
```python
# Schema 驗證
expect_table_columns_to_match_ordered_list(column_list=['id', 'name', 'email'])
expect_column_values_to_be_of_type(column='amount', type_='float')

# 完整性檢查
expect_column_values_to_not_be_null(column='customer_id')
expect_table_row_count_to_be_between(min_value=1000, max_value=100000)

# 準確性檢查
expect_column_values_to_be_between(column='age', min_value=13, max_value=120)
expect_column_values_to_be_in_set(column='status', value_set=['pending', 'paid', 'shipped'])

# 唯一性檢查
expect_column_values_to_be_unique(column='order_id')

# 一致性檢查
expect_column_pair_values_A_to_be_greater_than_B(column_A='end_date', column_B='start_date')
```

**AI 協作策略**:
- "為訂單表建立完整的 Expectation Suite"
- "解釋 Great Expectations 的 Checkpoint 執行流程"

---

### 3. 告警策略設計

**告警降噪技術**:
- **去重**:同一問題 1 小時內只告警一次
- **聚合**:10 分鐘內的多個告警合併為一條
- **優先級**:Critical 立即通知,Warning 批次通知
- **靜默期**:已知問題可設定靜默
- **告警疲勞**:單一來源每日最多 5 條告警

**告警訊息設計**:
```markdown
🚨 Critical: Data Quality Issue Detected

**Table**: orders
**Check**: NULL ratio in customer_id
**Status**: FAILED (15% NULL, threshold: 10%)
**Impact**: ~1,500 rows affected
**Timeline**: Started 2024-01-15 08:00

**Recommended Action**:
1. Check upstream ETL job logs
2. Verify customer_id is populated in source system
3. Review schema changes in last 24h

**View Details**: [Dashboard Link]
**Silence**: Reply "silence 24h" to mute
```

**AI 協作策略**:
- "設計告警訊息模板,包含:問題、影響、建議操作"
- "實作告警去重邏輯"

---

### 4. 數據血緣追蹤

**血緣圖設計**:
```
MySQL.orders → ETL.clean_orders() → DuckDB.orders_clean
                                        ↓
                                   ETL.aggregate_sales()
                                        ↓
                                   DuckDB.daily_sales_summary
                                        ↓
                                   Dashboard.sales_report
```

**血緣元數據**:
- **來源**:哪個表/API
- **轉換**:經過哪些處理函數
- **目標**:寫入哪個表
- **時間**:轉換時間戳
- **負責人**:誰維護這個轉換

**AI 協作策略**:
- "設計血緣 Schema:source、transformation、target、timestamp"
- "當 orders_clean 異常時,如何向上追溯到 MySQL.orders?"

---

## 🔧 技術棧建議

### 核心工具
- **品質框架**:Great Expectations(業界標準)
- **數據處理**:Pandas、Polars
- **儲存**:DuckDB(輕量)、PostgreSQL(生產)
- **告警**:Slack Webhook、SendGrid(Email)
- **監控儀表板**:Streamlit、Superset
- **血緣追蹤**:Apache Atlas、DataHub(企業級)或自建
- **AI 分析**:OpenAI API、Anthropic Claude

### 環境設定
```bash
# 安裝 Great Expectations
pip install great_expectations

# 初始化 GE 專案
great_expectations init

# 安裝其他依賴
pip install pandas duckdb streamlit slack-sdk openai
```

---

## 📊 成功標準

完成後應該能夠:

### 功能完整性
- [ ] 自動化品質檢查(Schema、完整性、準確性、一致性)
- [ ] 異常檢測(統計異常、業務規則違反)
- [ ] 實時告警(Slack/Email)
- [ ] 品質儀表板(趨勢、熱力圖、Drill-down)
- [ ] 數據血緣追蹤
- [ ] AI 根因分析和修復建議

### 品質指標
- [ ] **檢測率**:99% 的數據問題被自動檢測
- [ ] **誤報率**:< 5%(告警準確性)
- [ ] **響應時間**:問題發生後 5 分鐘內告警
- [ ] **修復時間**:平均從告警到修復 < 30 分鐘

### 業務價值
- [ ] 減少因數據問題導致的錯誤決策
- [ ] 數據團隊從被動救火變為主動預防
- [ ] 品質問題可追溯(知道哪裡出錯)
- [ ] 數據信任度提升(管理層信任報表)

---

## 🚀 擴展挑戰

### 進階挑戰 1:數據品質 SLA 定義
為每個核心表定義品質 SLA(如:品質分數 > 95%),並追蹤達成率。

**提示**:
- "定義 SLA:orders 表品質分數 > 95%,否則觸發升級告警"
- "追蹤 SLA 達成率:過去 30 天達成率 = 達成天數 / 30"
- "SLA 違反自動創建 Jira ticket"

---

### 進階挑戰 2:自動化修復
對於常見問題(如 NULL 值),實作自動化修復建議和執行。

**提示**:
- "建立修復 Playbook:NULL 值 → 填充預設值或刪除"
- "實作 dry-run 模式:展示修復後的數據但不實際修改"
- "需要人工批准後才執行修復"

---

### 進階挑戰 3:預測性品質監控
使用機器學習預測未來可能出現的品質問題。

**提示**:
- "訓練時間序列模型:預測未來 7 天的品質分數"
- "當預測分數 < 閾值時,提前告警"
- "特徵:歷史品質分數、數據量、上游系統健康度"

---

### 進階挑戰 4:多環境品質對比
比較開發/測試/生產環境的數據品質差異。

**提示**:
- "同一套 Expectation Suite 在三個環境執行"
- "視覺化:並排對比各環境通過率"
- "識別:生產環境失敗但測試環境通過的檢查(潛在問題)"

---

## 📚 相關資源

### 理論文件
- `理論/8.1_ETL管線快速原型.md` - 數據管線概念

### 快速上手
- `快速上手/ETL管線模板.md` - 數據管線參考

### 工具參考
- `工具速查/README.md` - Great Expectations 快速參考

### 其他情境
- `C01_完整ETL管線開發` - 數據管線設計
- `C03_銷售數據儀表板` - 儀表板實作參考

---

## 💬 AI 提示詞範例

### 架構設計階段
```
我需要為數據倉庫建立品質監控系統,監控對象包括:
- 10 個核心表(訂單、用戶、產品等)
- 每日新增 50,000+ 筆數據
- 需要檢查:Schema、完整性、準確性、一致性

請幫我:
1. 設計品質監控架構(檢查層、告警層、展示層)
2. 推薦技術棧(Great Expectations vs 自建)
3. 定義告警策略(什麼情況告警、優先級、降噪)

重點考量:
- 自動化執行(每小時檢查一次)
- 告警準確性(避免誤報)
- 易於維護(新增表時容易擴展)
```

### 實作階段
```
我用 Great Expectations 定義 Expectation,但不確定是否正確:

```python
# 需求:訂單金額應在 $1-$10,000 之間
suite.expect_column_values_to_be_between(
    column='amount',
    min_value=1,
    max_value=10000
)
```

問題:
1. 這個檢查會阻止超過 $10,000 的大訂單嗎?(實際有些訂單 > $10,000)
2. 應該用 95 百分位數動態設定閾值嗎?
3. 如何只告警極端異常(如 $100 萬),而不是所有超過 $10,000 的?

請給出改進建議。
```

### 告警設計階段
```
數據品質告警太多(每天 50+ 條),團隊疲於應對。

當前配置:
- 所有檢查失敗都告警
- 直接發送到 Slack #data-alerts
- 沒有優先級區分
- 沒有去重機制

請設計告警降噪策略:
1. 如何分級(Critical / Warning / Info)?
2. 如何去重(同一問題不重複告警)?
3. 如何聚合(多個小問題合併)?
4. 如何路由(Critical → On-call,Warning → 每日摘要)?
```

### 優化階段
```
品質檢查執行太慢(全表掃描需要 30 分鐘),影響 ETL 管線:

當前實作:
- Great Expectations 直接查詢生產 MySQL
- 每次檢查都是全表掃描
- 沒有增量檢查機制

請給出優化方案:
1. 如何實作增量檢查(只檢查新增數據)?
2. 是否應該在 ETL 過程中檢查(而不是事後)?
3. 如何平衡檢查覆蓋率和執行效率?
```

---

**相關情境題**:
- 🟢 B01_多源數據整合原型 - 數據整合基礎
- 🟡 C01_完整ETL管線開發 - 數據管線與品質結合
- 🟡 C03_銷售數據儀表板 - 儀表板實作
- 🟡 C05_混合資料處理工作流 - 複雜工作流設計
