# C02 - 企業文檔問答系統

## 📌 情境描述

### 業務背景
你的公司有 500+ 份技術文檔(API 文檔、開發指南、最佳實踐、故障排除手冊)散落在 Confluence、GitHub、Notion、PDF 文件中。新員工入職或遇到問題時,常常:
- 搜尋半小時找不到答案
- 重複詢問資深工程師同樣的問題
- 文檔過時但無人更新

### 現況痛點
- **知識碎片化**:同一主題散落在 5 個不同平台
- **搜尋效率低**:關鍵字搜尋常找不到相關文檔
- **上下文缺失**:找到文檔但不理解背景和關聯
- **更新不及時**:文檔過時但無人知曉

### 任務目標
使用 Claude Code 協助開發企業級文檔問答系統,實現:
- 統一知識庫整合(多源文檔自動同步)
- 語義搜尋(不只關鍵字,理解問題意圖)
- 帶來源引用的回答(可追溯原文)
- 對話式互動(連續提問,上下文記憶)
- 文檔更新自動同步

---

## 🎯 學習目標

完成本情境後,你將能夠:

- [ ] **構建生產級 RAG 系統**:從原型到可部署的完整架構
- [ ] **多源文檔處理**:Markdown、PDF、HTML、Docx 統一處理
- [ ] **智能分塊策略**:不同文檔類型的最佳 chunking 方法
- [ ] **向量數據庫選型**:本地開發(Chroma)vs 生產(Pinecone/Weaviate)
- [ ] **對話管理**:實作多輪對話的上下文記憶
- [ ] **來源追蹤**:回答附帶原文引用和連結
- [ ] **系統監控**:追蹤查詢日誌、回答品質、系統效能
- [ ] **增量更新**:文檔變更自動重建索引

**時間估計**:2.5-3 小時

---

## 🏗️ 系統架構

```
┌─────────────────────────────────────────────────┐
│           Document Sources (文檔來源)            │
├──────────┬──────────┬──────────┬───────────────┤
│ GitHub   │Confluence│  Notion  │  Local Files  │
│  (.md)   │  (HTML)  │  (API)   │  (.pdf/.docx) │
└────┬─────┴────┬─────┴────┬─────┴───────┬───────┘
     │          │          │             │
     └──────────┴──────────┴─────────────┘
                      ▼
          ┌─────────────────────┐
          │  Document Ingestion │
          │  - Format detection │
          │  - Metadata extract │
          │  - Auto sync        │
          └──────────┬──────────┘
                     ▼
          ┌─────────────────────┐
          │   Text Processing   │
          │  - Chunking         │
          │  - Embedding        │
          │  - Deduplication    │
          └──────────┬──────────┘
                     ▼
          ┌─────────────────────┐
          │   Vector Database   │
          │   (Pinecone/Chroma) │
          │  - Semantic search  │
          │  - Metadata filter  │
          └──────────┬──────────┘
                     │
                     │ Query
                     ▼
          ┌─────────────────────┐
          │   Retrieval Chain   │
          │  - Query expansion  │
          │  - Reranking        │
          │  - Source tracking  │
          └──────────┬──────────┘
                     ▼
          ┌─────────────────────┐
          │   LLM Generation    │
          │  - GPT-4 / Claude   │
          │  - Citation format  │
          │  - Context window   │
          └──────────┬──────────┘
                     ▼
          ┌─────────────────────┐
          │  Conversation Store │
          │  - Chat history     │
          │  - User feedback    │
          └──────────┬──────────┘
                     │
                     ▼
          ┌─────────────────────┐
          │     Web UI / API    │
          │  - Chat interface   │
          │  - Source display   │
          │  - Feedback button  │
          └─────────────────────┘
```

---

## 📋 核心任務

### 階段一:文檔攝取管線(40 分鐘)

**任務**:
1. 實作多格式文檔載入器(Markdown、PDF、Docx、HTML)
2. 自動提取元數據(標題、作者、更新時間、來源 URL)
3. 建立增量同步機制(僅處理新增/修改文檔)
4. 文檔預處理(清理 HTML、移除無意義內容)

**與 AI 協作要點**:
- "設計一個統一的 DocumentLoader 介面,支援 Markdown、PDF、HTML"
- "使用 LangChain UnstructuredFileLoader 載入多種格式"
- "實作文檔指紋(hash),只處理變更的文件"
- "為每份文檔提取元數據:title、source_url、last_updated"

**檢查點**:
- [ ] 可以載入 Markdown、PDF、Docx、HTML 文檔
- [ ] 元數據正確提取(標題、來源、更新時間)
- [ ] 增量同步:只處理新增/修改文檔
- [ ] 文檔數量統計準確

---

### 階段二:智能分塊與向量化(40 分鐘)

**任務**:
1. 實作語義感知的文檔分塊(不破壞段落結構)
2. 選擇合適的 Embedding 模型(OpenAI vs 開源)
3. 生成向量並存入向量數據庫
4. 實作去重邏輯(避免重複內容)

**與 AI 協作要點**:
- "比較 RecursiveCharacterTextSplitter vs SemanticChunker,哪個更適合技術文檔?"
- "設定 chunk_size=1000、overlap=200,解釋這個選擇的原因"
- "使用 text-embedding-3-small,比較成本與效果"
- "實作 chunk-level 去重,計算 embedding 相似度"

**檢查點**:
- [ ] 分塊不破壞段落完整性(不在句子中間切斷)
- [ ] 每個 chunk 保留元數據(來源文檔、位置)
- [ ] 向量成功存入 Pinecone/Chroma
- [ ] 重複內容被識別並跳過

---

### 階段三:檢索鏈實作(40 分鐘)

**任務**:
1. 實作混合檢索(向量 + 關鍵字)
2. 查詢擴展(Query Expansion)提升召回
3. 重排序(Reranking)提升準確性
4. 來源追蹤(每個答案標註來源文檔)

**與 AI 協作要點**:
- "使用 MultiQueryRetriever 自動生成 3 個相似查詢"
- "實作 MMR(Maximal Marginal Relevance)增加結果多樣性"
- "使用 Cohere Rerank API 對檢索結果重排序"
- "確保每個引用包含:文檔標題、段落內容、URL"

**檢查點**:
- [ ] 語義搜尋準確(測試:"如何部署應用" 能找到部署相關文檔)
- [ ] 查詢擴展生效(一個查詢生成 3 個變體)
- [ ] 重排序提升相關性(前 3 個結果都高度相關)
- [ ] 答案包含來源引用和 URL

---

### 階段四:對話式生成與引用(30 分鐘)

**任務**:
1. 實作 ConversationalRetrievalChain(支援多輪對話)
2. 對話歷史管理(保留最近 5 輪)
3. 引用格式化(Markdown 引用塊 + 超連結)
4. 回答品質控制(無法回答時明確說明)

**與 AI 協作要點**:
- "使用 ConversationBufferMemory 保留對話歷史"
- "設計 prompt:要求 LLM 明確引用來源並給出 [1][2] 標註"
- "當檢索不到相關文檔時,回答'抱歉,我在文檔庫中找不到相關資訊'"
- "實作 streaming response,提升用戶體驗"

**檢查點**:
- [ ] 可以連續提問,AI 理解上下文
- [ ] 答案末尾有格式化的來源列表
- [ ] 無相關文檔時明確告知(不編造答案)
- [ ] 回答逐字顯示(streaming)

---

### 階段五:系統監控與優化(30 分鐘)

**任務**:
1. 記錄查詢日誌(問題、檢索結果、回答)
2. 使用者反饋機制(讚/踩)
3. 效能監控(檢索時長、生成時長)
4. 自動更新機制(定時同步文檔)

**與 AI 協作要點**:
- "使用 LangSmith 或 LangFuse 追蹤每次查詢"
- "設計反饋表單,收集回答品質評分"
- "實作 Cron job 每小時同步 GitHub 文檔"
- "監控 token 使用量,預估成本"

**檢查點**:
- [ ] 每次查詢記錄到日誌(問題、來源、時長)
- [ ] 用戶可以對回答點讚/踩
- [ ] 效能指標:檢索 < 500ms、生成 < 3s
- [ ] 文檔每小時自動同步

---

## 💡 學習重點

### 1. RAG 系統設計模式

**關鍵概念**:
- **Chunking 策略**:固定長度 vs 語義分割 vs 滑動窗口
- **Retrieval 方法**:Dense(向量) vs Sparse(BM25) vs Hybrid
- **Generation 策略**:Stuffing vs Map-Reduce vs Refine

**AI 協作策略**:
- "解釋 RAG 中 chunk_size 和 overlap 如何影響檢索品質"
- "比較 Hybrid Search(向量+關鍵字) vs 純向量搜尋的優缺點"

---

### 2. 向量數據庫選型

**關鍵概念**:
- **本地開發**:Chroma、FAISS(免費、易用)
- **雲端生產**:Pinecone、Weaviate、Qdrant(高效能、可擴展)
- **自建生產**:Milvus、pgvector(完全控制)

**決策樹**:
```
文檔量 < 10,000 且無需多用戶 → Chroma(本地)
需要高可用、多區域部署 → Pinecone(託管)
需要完全控制、私有部署 → pgvector(PostgreSQL 擴展)
超大規模(百萬級向量) → Milvus(分散式)
```

**AI 協作策略**:
- "比較 Chroma vs Pinecone 在成本、效能、易用性的差異"
- "我的文檔量是 50,000,需要支援 100 並發,推薦哪個向量數據庫?"

---

### 3. 文檔處理最佳實踐

**關鍵概念**:
- **元數據豐富化**:保留文檔結構(標題層級、章節)
- **去重策略**:embedding 相似度 > 0.95 視為重複
- **增量更新**:文檔 hash + 時間戳避免全量重建

**AI 協作策略**:
- "PDF 中的表格和圖片如何處理?直接忽略還是用 OCR?"
- "實作文檔指紋,只處理變更文件"

---

### 4. 對話品質優化

**關鍵概念**:
- **查詢理解**:重寫模糊問題,擴展簡短查詢
- **引用可追溯**:每個答案連結到原文
- **幻覺控制**:無相關文檔時明確告知

**AI 協作策略**:
- "設計 prompt 讓 LLM 明確區分'文檔中有'和'我推測的'"
- "實作 HyDE(Hypothetical Document Embeddings)提升召回"

---

## 🔧 技術棧建議

### 核心工具
- **RAG 框架**:LangChain / LlamaIndex
- **向量數據庫**:
  - 開發:Chroma、FAISS
  - 生產:Pinecone、Weaviate、Qdrant
- **Embedding 模型**:
  - OpenAI `text-embedding-3-small` (便宜)
  - OpenAI `text-embedding-3-large` (效果好)
  - 開源:sentence-transformers
- **LLM**:GPT-4、Claude 3.5 Sonnet
- **文檔載入**:Unstructured、PyPDF2、python-docx
- **監控**:LangSmith、LangFuse
- **Web UI**:Streamlit、Chainlit

### 環境設定
```bash
# 安裝依賴
pip install langchain openai chromadb unstructured python-dotenv streamlit

# (可選)安裝 Pinecone
pip install pinecone-client

# 設定環境變數
OPENAI_API_KEY=sk-...
PINECONE_API_KEY=...
PINECONE_ENVIRONMENT=...
```

---

## 📊 成功標準

完成後應該能夠:

### 功能完整性
- [ ] 支援多種文檔格式(Markdown、PDF、Docx、HTML)
- [ ] 語義搜尋準確(相關文檔排在前 3)
- [ ] 答案包含來源引用和連結
- [ ] 支援多輪對話(理解上下文)
- [ ] 文檔自動同步(每小時)

### 品質指標
- [ ] **檢索準確性**:Top-3 命中率 > 80%
- [ ] **回答品質**:用戶滿意度 > 85%
- [ ] **效能**:檢索 < 500ms、生成 < 3s
- [ ] **可用性**:7x24 穩定運行

### 使用者體驗
- [ ] 回答逐字顯示(streaming)
- [ ] 來源可點擊跳轉到原文
- [ ] 可以點讚/踩提供反饋
- [ ] 無相關文檔時明確告知

---

## 🚀 擴展挑戰

### 進階挑戰 1:多模態支援
擴展系統支援圖片、表格、程式碼片段的問答。

**提示**:
- "使用 Unstructured 提取 PDF 中的表格"
- "程式碼片段用專門的 Code Splitter 分塊"
- "圖片用 GPT-4V 生成描述後索引"

---

### 進階挑戰 2:知識圖譜增強
結合知識圖譜(Neo4j)增強實體關聯理解。

**提示**:
- "使用 spaCy 提取實體(產品名、技術名詞)"
- "建立實體關係圖存入 Neo4j"
- "檢索時同時查詢向量 DB 和知識圖譜"

---

### 進階挑戰 3:多租戶隔離
實作多團隊使用,各團隊只能查詢自己的文檔。

**提示**:
- "在向量 DB 中用 metadata filter 實現租戶隔離"
- "實作基於 JWT 的身份驗證"
- "每個租戶有獨立的文檔來源配置"

---

### 進階挑戰 4:自動評估系統
建立自動化評估,追蹤 RAG 系統品質變化。

**提示**:
- "建立測試集:100 個問題 + 期望答案"
- "使用 RAGAS 框架評估:faithfulness、relevancy"
- "每次更新後自動運行評估"

---

## 📚 相關資源

### 理論文件
- `理論/8.2_RAG系統快速搭建.md` - RAG 基本原理
- `理論/8.3_資料分析自動化.md` - 自動化概念

### 快速上手
- `快速上手/10分鐘搭建RAG系統.md` - 最簡版本

### 工具參考
- `工具速查/README.md` - 向量數據庫選型決策樹

### 其他情境
- `B02_RAG系統原型搭建` - 簡化版 RAG 原型
- `C01_完整ETL管線開發` - 數據管線設計思路

---

## 💬 AI 提示詞範例

### 架構設計階段
```
我需要為公司建立企業文檔問答系統,文檔來源包括:
- GitHub 上的 Markdown 技術文檔(500 個文件)
- Confluence 的 HTML 頁面(300 頁)
- 本地 PDF 手冊(50 個文件)

請幫我:
1. 設計 RAG 系統架構(文檔攝取、向量化、檢索、生成)
2. 推薦合適的向量數據庫(考慮成本和易用性)
3. 給出文檔分塊策略(chunk_size、overlap)

重點考量:
- 需要增量更新(不用每次全量重建)
- 回答要包含來源引用
- 支援多輪對話
```

### 實作階段
```
目前實作 RAG 檢索鏈,但發現回答常常不準確:

```python
# 當前代碼
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever
)
```

問題:
1. 有時檢索到的文檔不相關
2. 答案沒有引用來源
3. 無相關文檔時會編造答案

請幫我改進:
1. 如何提升檢索準確性?
2. 如何讓答案包含來源引用?
3. 如何控制幻覺?
```

### 優化階段
```
RAG 系統已上線,但效能有問題:
- 檢索需要 2 秒(目標 < 500ms)
- 生成需要 8 秒(目標 < 3s)
- 每天 token 成本 $50(目標 < $20)

我的配置:
- 向量 DB:Chroma(本地)
- Embedding:text-embedding-3-large
- LLM:GPT-4(每次檢索 k=10)

請幫我優化:
1. 如何加速檢索?
2. 如何降低 LLM 成本?
3. 需要遷移到 Pinecone 嗎?
```

---

**相關情境題**:
- 🟢 B02_RAG系統原型搭建 - 簡化版入門
- 🟡 C03_銷售數據儀表板 - 數據可視化實作
- 🟡 C04_資料品質監控系統 - 系統監控思路
